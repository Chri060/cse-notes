\section{Introduction}

When verifying software, we often compare two approaches: testing and proof. 
Testing, also known as dynamic analysis, involves executing a program with various inputs to observe its behavior.
It provides practical insights but is limited to a finite set of execution traces, meaning it cannot guarantee the absence of errors. 
In contrast, proofs, or static analysis, aim to establish correctness mathematically, ensuring that certain errors cannot occur. 
While proofs offer exhaustive guarantees, they are often impractical due to their complexity and limited automation.

Despite their impracticality in many real-world scenarios, learning proofs is valuable. 
They help us develop a structured way of thinking about program correctness, assist in software development and code inspection, and provide foundational insights into automated theorem provers.

\subsection{Correctness}
Program correctness defines a contract between the client and the implementation.
Given an initial condition, a function $f$ must ensure a specific outcome after execution.

This relationship is formally described using preconditions (assumptions about inputs) and post conditions (expected outcomes), which are expressed as predicates (boolean functions over the program state).

\begin{definition}[\textit{Function correctness}]
    A function is considered correct with respect to its specification if, given a valid precondition, it produces the expected post condition upon execution.
\end{definition}

\begin{definition}[\textit{Program partial correctness}]
    A program is partially correct if, whenever the precondition holds and the program terminates, the post condition also holds.
\end{definition}

\begin{definition}[\textit{Program total correctness}]
    A program is totally correct if, given a valid precondition, it both terminates and ensures the post condition holds.
\end{definition}