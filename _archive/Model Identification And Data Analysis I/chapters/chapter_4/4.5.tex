\section{Non-zero mean ARMA process}

Consider the ARMA process:
\[y(t)=\dfrac{C(z)}{A(z)}e(t) \qquad e(t)\sim WN(\mu,\lambda^2)\]
The expected value is:
\[\mathbb{E}\left[y(t)\right]=W(1)\mu=\bar{y}\]
Assuming the process is in canonical representation, we can express it as:
\[\begin{cases}
    \tilde{y}(t)=y(t)-\bar{y} \\
    \tilde{e}(t)=e(t)-\mu 
\end{cases} \rightarrow \tilde{y}(t)=W(z)\tilde{e}(t)\]
Applying the previously found prediction algorithm:
\begin{enumerate}
    \item Perform the long division.
    \item Take $\frac{F(z)}{A(z)}\tilde{e}(t)$. 
    \item Use the whitening filter.
\end{enumerate}
We obtain:
\[\hat{\tilde{y}}(t+k\mid t)=\dfrac{F(z)}{C(z)}\tilde{y}(t)\]

\paragraph*{Trivial solution}
To obtain the prediction for the original problem, we follow these steps:
\begin{itemize}
    \item Remove the mean from each data point: $\tilde{y}=y(t)-\bar{y}$. 
    \item Compute $\hat{\tilde{y}}(t+k\mid t)$. 
    \item Finally, the predicted value is given by: $\hat{y}(t+k\mid t)=\hat{\tilde{y}}(t+k\mid t)+\bar{y}$.
\end{itemize}

\paragraph*{Optimized solution}
Alternatively, we can integrate the computation of the correct predictor by modifying the formula.

Given that $y(t+k\mid t)=\tilde{y}(t+k\mid t)+\bar{y}$, we deduce:
\[\hat{y}(t+k\mid t)=\hat{\tilde{y}}(t+k\mid t)+\bar{y}=\dfrac{F(z)}{C(z)}\tilde{y}(t)+\bar{y}=\dfrac{F(z)}{C(z)}(y(t)-\bar{y})+\bar{y} \]
Asymptotically, $\dfrac{F(z)}{C(z)}\bar{y}$ tends to $\dfrac{F(1)}{C(1)}\bar{y}$:
\[\hat{y}(t+k\mid t)=\dfrac{F(z)}{C(z)}(y(t)-\bar{y})+\bar{y}=\dfrac{F(z)}{C(z)}y(t) + \left(1-\dfrac{F(1)}{C(1)}\right)\bar{y}\]
This represents the form of the predictor for an ARMA process with non-zero mean.