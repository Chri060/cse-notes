\section{Generative models}

The goal of generative models is to generate new data samples that resemble those in a given training set. 
These models can be applied to various tasks such as data augmentation, simulation, and planning.
They are particularly useful for solving inverse problems like super-resolution, inpainting, and colorization. 
Generative models can also be used to produce realistic samples for artwork creation.

In addition to their direct applications, training generative models often helps infer latent representations that can serve as valuable general features. 
These models aim to capture the distribution of natural images. 
By learning such distributions, generative models can act as powerful regularizers in other tasks.

Beyond specific applications like image generation, the advent of models like Generative Adversarial Networks introduced a new training paradigm. 
Although this was a major breakthrough, the advent of more advanced foundational models has since revolutionized the use of generative models.

\subsection{Generative Adversarial Networks}
Generative Adversarial Networks offer a unique approach to generative modeling by sidestepping the need for an explicit density model $\phi_s$ describing the manifold of natural that describes the manifold of natural images. 
Instead, Generative Adversarial Networks aim to find a model that can generate samples resembling the training data. 

Rather than sampling directly from a complex distribution $\phi_s$ Generative Adversarial Networks work by sampling a seed from a known distribution $\phi_z$ (often referred to as noise) and passing it through a learned transformation. 
This transformation generates realistic samples that appear to be drawn from the original data distribution $\phi_s$. 
The Neural Network learns this transformation in an unsupervised manner.

\paragraph*{Loss function}
The most significant challenge in Generative Adversarial Networks is designing a suitable loss function to evaluate the realism of the generated images. 
The solution is to train two Neural Networks that address different tasks, competing in a two-player (adversarial) game:
\begin{itemize}
    \item \textit{Generator} $\mathcal{G}$: this network produces realistic samples by taking random noise as input. 
        The generator's goal is to fool the discriminator into thinking the generated samples are real.
    \item \textit{Discriminator} $\mathcal{D}$: this network takes an image as input and assesses whether it is real (from the training set) or generated by the generator. 
        The discriminator's task is to distinguish between real and fake images.
\end{itemize}
During training, both networks are optimized simultaneously, and at the end of the process, only the generator is kept. 
The discriminator becomes redundant because, after training, it can no longer distinguish between real and fake images. 
Notably, the generator has never directly seen an image from the training set $S$.

\paragraph*{Discriminator}
A good discriminator should exhibit the following properties:
\begin{enumerate}
    \item $\mathcal{D}(s,\theta_d)$ should be maximized when $s\in S$ (true image from the training set).
    \item $1-\mathcal{D}(s,\theta_d)$ should be maximized when $s$ is generated by $\mathcal{G}$. 
    \item $1-\mathcal{D}(\mathcal{G}(z,\theta_g),\theta_d)$ should be maximized when $z\sim\phi_z$ (random noise).
\end{enumerate}
To train the discriminator, the binary cross-entropy loss is maximized:
\[\max_{\theta_d}\left(\mathbb{E}_{s\sim \theta_s}[\log\mathcal{D}(s,\theta_d)]+\mathbb{E}_{z\sim\theta_s}[\log\left(1-\mathcal{D}(\mathcal{G}(z,\theta_g),\theta_d)\right)]\right)\]
The first term ensures that the discriminator classifies real images correctly, while the second term ensures it classifies generated images as fake.

\paragraph*{Generator}
The generator's goal is to minimize the discriminator's ability to distinguish real from fake. 
Hence, the objective for the generator is:
\[\min_{\theta_g}\max_{\theta_d}\left(\mathbb{E}_{s\sim \theta_s}[\log\mathcal{D}(s,\theta_d)]+\mathbb{E}_{z\sim\theta_s}[\log\left(1-\mathcal{D}(\mathcal{G}(z,\theta_g),\theta_d)\right)]\right)\]
This approach is solved using an iterative numerical method, typically stochastic gradient descent.

\paragraph*{Conclusions}
The training of Generative Adversarial Networks is notoriously unstable and requires careful synchronization between the generator and discriminator steps. 
Later advancements, such as the Wasserstein Generative Adversarial Network, have addressed some of these instability issues. 
Generative Adversarial Networks are trained using standard backpropagation and dropout, with no direct evaluation of the generator during training.

One challenge in Generative Adversarial Network training is the difficulty in quantitatively assessing the generator's performance. 
Since the generator's output is implicitly defined, evaluating its effectiveness remains a complex task.