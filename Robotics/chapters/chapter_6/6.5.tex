\section{Sampling-based methods}

Sampling-based motion planning is driven by the impracticality and time-consuming nature of constructing explicit representations of collision-free space.
Conversely, checking if a position is in free space is rapid, facilitated by fast collision-checking algorithms capable of testing configurations or short paths for collision-free status in less than 0.001 seconds.

The fundamental approach involves sampling the space of interest, connecting sampled points via simple paths, checking path collision status, and subsequently searching the resulting graph.

\subsection{Probabilistic roadmap algorithm}
\begin{algorithm}[H]
    \caption{Probabilistic roadmap construction algorithm}
        \begin{algorithmic}[1]
            \State{Pick uniformly at random $s$ configurations in $F$ and create $M$, the set of milestones}
            \State{Construct the graph $R=(M, L)$ where $L$ is every pair of milestones that see each other}
            \State{Call $R$ the roadmap}
        \end{algorithmic}
\end{algorithm}
\begin{algorithm}[H]
    \caption{Probabilistic roadmap algorithm}
        \begin{algorithmic}[1]
            \For{$i=\left\{b,e\right\}$}
                \If{there is a milestone $m$ that sees $q_i$}
                    \State{$m_i\leq m$}
                \Else
                    \Repeat 
                        \State{Select $q$ in $F$ at random near $q_i$ until $q$ sees both $q_i$ and a milestone $m$}
                        \If{all $t$ trials fail} 
                            \State\Return{Failure}
                        \Else 
                            \State{$m_i=m$}
                        \EndIf
                    \Until{$count=t$}
                \EndIf
                \If{$m_b$ and $m_e$ are in the same connected component of the roadmap} 
                    \State\Return{Path connecting them}
                \Else
                    \State\Return{No path}
                \EndIf
            \EndFor
        \end{algorithmic}
\end{algorithm}
Sample-based methods incrementally construct a search tree by progressively enhancing resolution, eliminating the necessity for a roadmap. 
It's an incremental sampling and searching approach without any parameter tuning. 
Ultimately, the tree densely covers the space, guided by a dense sequence of samples during construction.

\subsection{Rapidly Exploring Dense Trees}
\begin{algorithm}[H]
    \caption{Simple Rapidly Exploring Dense Trees}
        \begin{algorithmic}[1]
            \State{$\mathcal{G}$.init($q_0$)}
            \For{$i=1$ \textbf{to} $k$} 
                \State{$\mathcal{G}$.add\_vertex($\alpha(i)$)}
                \State{$q_n=nearest(S(\mathcal{G}),\alpha(i))$}
                \State{$\mathcal{G}$.add\_edge($q_n,\alpha(i)$)}
            \EndFor 
        \end{algorithmic}
\end{algorithm}
Here, $\alpha$ is a dense sequence of samples in $C$, $\alpha(i)$ is the $i$-th sample of the sample sequence, $G(V, E)$ is the topological representation of Rapidly exploring dense trees, $S \subset C_{\text{free}}$ is the set of points reached by $\mathcal{G}$. 

Some years later the same algorithm were improved and became: 
\begin{algorithm}[H]
    \caption{Rapidly Exploring Dense Trees}
        \begin{algorithmic}[1]
            \State{$\mathcal{G}$.init($q_0$)}
            \For{$i=1$ \textbf{to} $k$} 
                \State{$q_n=nearest(S,\alpha(i))$}
                \State{$q_s=stopping\_configuration(q_n,\alpha(i))$}
                \If{$q_s\neq q_n$}
                    \State{$\mathcal{G}$.add\_vertex($q_s$)}
                    \State{$\mathcal{G}$.add\_edge($q_n,q_s$)}
                \EndIf
            \EndFor
        \end{algorithmic}
\end{algorithm}

Some years later the same algorithm were improved and became: 
\begin{algorithm}[H]
    \caption{Balanced Bidirectional Rapidly Exploring Dense Trees}
        \begin{algorithmic}[1]
            \State $T_a.\text{init}(q_1)$
            \State $T_b.\text{init}(q_G)$
            \For{$i = 1$ \textbf{to} $K$}
                \State $q_n=nearest(S_a, \alpha(i))$
                \State $q_s=stopping\_configuration(q_n, \alpha(i))$
                \If{$q_s \neq q_n$}
                    \State $T_a.add\_vertex(q_s)$
                    \State $T_a.add\_edge(q_n, q_s)$
                    \State $q_n^{\prime} =nearest(S_b, q_s)$
                    \State $q_s^{\prime} =stopping\_configuration(q_n^{\prime}, q_s)$
                    \If{$q_s^{\prime} \neq q_n^{\prime}$}
                        \State $T_b.add\_vertex(q_s^{\prime})$
                        \State $T_b.add\_edge(q_n^{\prime}, q_s^{\prime})$
                    \EndIf
                    \If{$q_s = q_n$ and $q_s^{\prime} = q_n^{\prime}$}
                        \State\Return{solution}
                    \EndIf
                \EndIf
                \If{$\left\lvert T_b\right\rvert  > \left\lvert T_a\right\rvert $}
                    \State{$swap(T_a, T_b)$}
                \EndIf
            \EndFor
            \State \Return failure
        \end{algorithmic}
\end{algorithm}


\subsection{Rapidly Exploring Random Trees}
RRT enhances the basic RDT by:
\begin{itemize}
    \item Steering the system towards random samples in accordance with kinodynamics.
    \item Biasing the tree towards unexplored regions through Voronoi bias.
\end{itemize}

\begin{algorithm}[H]
    \caption{Balanced Bidirectional Rapidly Exploring Dense Trees}
        \begin{algorithmic}[1]
            \State $\tau=InitializeTree()$
            \State $\tau=InsertNode(\varnothing, z_{\text{init}}, \tau)$
            \For{$i = 1$ \textbf{to} $N$}
                \State $z_{\text{rand}} = Sample(i)$
                \State $z_{\text{nearest}} = \text{Nearest}(\tau, z_{\text{rand}})$
                \State $(x_{\text{new}}, u_{\text{new}}, T_{\text{new}}) = \text{Steer}(z_{\text{nearest}}, z_{\text{rand}})$
                \If{$ObstacleFree(x_{\text{new}})$}
                    \State $\tau = \text{InsertNode}(z_{\text{new}}, \tau)$
                \EndIf
            \EndFor
            \State \Return $\tau$
        \end{algorithmic}
\end{algorithm}
The quality of RRT exploration depends greatly on the chosen distance metric, especially in the context of non-holonomic systems, which pose challenges in metric selection.

Key advantages include asymptotic completeness, effectiveness in high-dimensional state spaces, elimination of the need for a two-state boundary value solver, simple implementation, and adaptability to constrained platforms.

However, drawbacks include the lack of asymptotic optimality, absence of optimality guarantees, generation of jerky paths within finite time, and limited potential for offline computations.

\paragraph*{Extensions}
Several extensions have been suggested for the fundamental Rapidly Exploring Random Trees algorithm:
\begin{itemize}
    \item \textit{Bidirectional RRT}: this approach involves growing two trees simultaneously from the start and goal states, with frequent attempts to merge them.
    \item \textit{Goal-biased RRT}: this variant samples the goal state every nth sample, balancing exploration and exploitation.
    \item \textit{RRT*}: introducing a local rewiring step, RRT* aims to achieve asymptotic optimality.
\end{itemize}
These extensions offer various advantages: they are asymptotically complete and provide an asymptotically optimal guarantee. 
They perform well in high-dimensional state spaces, do not necessitate a two-state boundary value solver, are straightforward to implement, and can handle constrained platforms with ease.

However, there are drawbacks to consider: they require a two-state boundary value solver for the rewiring process, tend to produce jerky paths within finite time, and have limited potential for offline computations.