\section{POSIX Threads}

\paragraph*{Threads}
A thread is an independent unit of execution within a process, capable of running concurrently with other threads. 
Each thread has its own local data, but can access the resources shared by the parent process. 
Unlike a full process, which includes information about resources and execution state, a thread is more lightweight. 
A single process can spawn multiple threads, each of which operates as an independent stream of instructions.

Threads are managed by the operating system, which schedules them for execution. 
They can run in parallel, allowing for more efficient use of resources. 

In this sense, threads provide a form of implicit communication, as they can read and write shared variables. 
However, because multiple threads can access the same memory location, this requires explicit synchronization to prevent conflicts. 
Without proper synchronization, concurrent threads may cause unpredictable behavior, particularly when they attempt to modify the same data simultaneously.

Threads can be created dynamically during execution, and are generally more efficient than creating multiple processes since they share resources, avoiding the overhead associated with full process management. 
Since threads operate independently but share the same memory space, synchronization mechanisms such as locks or semaphores must be used to prevent conflicting operations.

\paragraph*{Race condition}
A race condition occurs when two or more threads access the same variable concurrently, and at least one of them performs a write operation. 
Since these accesses are not synchronized, there is a risk that the threads may interfere with each other, leading to inconsistent or incorrect results. 
To prevent race conditions, synchronization mechanisms are required, which ensure that only one thread can modify the shared resource at a time.
This can be achieved through various methods, such as using mutexes, locks, or atomic operations. 
The programmer is responsible for managing the synchronization of threads, often using libraries, compiler directives, or other tools designed to handle parallelism and ensure the integrity of shared data.

\paragraph*{PThreads}
POSIX Threads provide a standardized API for managing threads in multi-threaded programming, enabling developers to efficiently execute tasks concurrently.

Threads are peers, meaning that once created, they operate independently without any inherent hierarchy. 
Threads can also create additional threads without any dependencies or constraints. 
The maximum number of threads is determined by the system's implementation.

\paragraph*{Creation}
Threads are created using the \texttt{pthread\_create} function:
\begin{lstlisting}[style=C]
int pthread_create()
\end{lstlisting}
This function initializes a new thread that begins execution with the specified start routine.

\paragraph*{Termination}
A thread terminates naturally when its start routine returns or the process in which it resides exits. 
Threads can also be explicitly terminated using the following functions:
\begin{lstlisting}[style=C]
// Exit the calling thread
int pthread_exit()
// Exit a specific thread
int pthread_cancel()
\end{lstlisting}

\paragraph*{Joining}
To wait for a thread to finish execution, the \texttt{pthread\_join} function is used:
\begin{lstlisting}[style=C]
int pthread_join()
\end{lstlisting}
When a thread is joined, the calling thread is blocked until the specified thread terminates. 
Threads can be created as joinable (default) or detached. 
Joinable threads must be joined to release their resources, while detached threads release their resources automatically upon termination.

\subsection{Synchronization mechanisms}
Synchronization is essential in multi-threaded programming to coordinate the execution of threads and protect shared resources. 

\paragraph*{Barriers}
Barriers synchronize multiple threads at a specific point in their execution. 
All threads in a group must reach the barrier before any can proceed:
\begin{lstlisting}[style=C]
// Initialize a barrier
int pthread_barrier_init()
// Wait at a barrier
int pthread_barrier_wait()
\end{lstlisting}

\paragraph*{Mutex}
Mutexes (mutual exclusion locks) ensure that only one thread accesses a critical section at a time.
\begin{lstlisting}[style=C]
pthread_mutex_lock(&my_lock);
/* critical section */
pthread_mutex_unlock(&my_lock);
\end{lstlisting}
If a thread attempts to lock a mutex that is already locked, it will block until the mutex becomes available. 
Alternatively, \texttt{pthread\_mutex\_trylock} can be used to attempt locking without blocking.

\paragraph*{Condition variables}
Condition variables allow threads to wait for specific conditions to be met. 
They are typically used in conjunction with a mutex to signal state changes between threads:
\begin{lstlisting}[style=C]
pthread_mutex_lock(&my_mutex);
while (!condition_met) pthread_cond_wait(&my_cond, &my_mutex);
/* condition is now met */
pthread_mutex_unlock(&my_mutex);

// Signal or broadcast to waiting threads
pthread_cond_signal(&my_cond);
pthread_cond_broadcast(&my_cond);
\end{lstlisting}
Condition variables provide a powerful mechanism for coordinating thread activities based on dynamic conditions.