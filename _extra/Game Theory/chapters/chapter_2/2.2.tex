\section{Extensive games}

An extensive game with perfect information consists of:
\begin{enumerate}
    \item A finite set $N = \{1,\dots,n\}$ of players. 
    \item A game tree $(V,E,x_0)$.
    \item A partition of the non-leaf vertices into sets ${P_1, P_2, \dots , P_{n+1}}$.
    \item A probability distribution for each vertex in $P_{n+1}$, defined on the edges from that vertex to its children.
    \item A $n$-dimensional vector attached to each leaf (list of possible outcomes). 
\end{enumerate}
\noindent The set $P_i$, for $i \leq n$, consists of nodes where Player $i$ must choose a child of $v$, representing a possible move by that player.
$P_{n+1}$ is the set of nodes where chance plays a role. 
When $P_{n+1}$ is empty, the game does not admit any random event. 

\subsection{Solution}
To determine the optimal outcome, we apply the axioms of rationality to the game tree, finding the solution to the extensive game. 

\begin{definition}[\textit{Length}]
    The length of a game is defined as the length of the longest path in the game tree.
\end{definition}
\noindent The fifth rationality assumption allows us to solve games of length 1, while the fourth rationality assumption allows us to solve games of length $i + 1$ if all games of length at most $i$ have already been solved.
The iterative process where we work backwards from the leaves of the tree to the root to determine the optimal sequence of actions is called backward induction.
\begin{theorem}[First rationality theorem]
    The rational outcomes of a finite game with perfect information are those determined by the backward induction procedure.
\end{theorem}
Backward induction can be applied because every vertex $v$ in the game is the root of a sub-game consisting of all the vertices that follow $v$. 

\subsection{Possible outcomes}
In extensive games there may be more than one possible outcome. 
\begin{theorem}[Von Neumann]
    In the game of chess, one and only one of the following alternatives holds:
    \begin{enumerate}
        \item The white has a way to win, no matter what the black does.
        \item The black has a way to win, no matter what the white does.
        \item Both white and black can force at least a draw, regardless of the opponent's actions.
    \end{enumerate}
\end{theorem}
\begin{proof}
    Assume the game has a finite length of $2k$ moves (each player makes $k$ moves). 
    Let $a_i$ represent white's moves, and $b_i$ represent black's moves. 
    The first possibility in the theorem can be formulated as follows:
    \[\exists a_1 \mid \forall b_1 \exists a_2 \mid \forall b_2 \dots \exists a_k \mid \forall b_k \implies \text{white wins}\]
    Now, suppose this is false, resulting in its negation:
    \[\forall a_1 \exists b_1 \mid \forall a_2 \mid \exists b_2 \mid \dots \forall a_k \mid \exists b_k \implies \text{white does not win}\]
    This means black has the possibility to prevent White from winning, ensuring at least a draw.
    This applies also to the second possibility in the same way. 
\end{proof}
\begin{corollary}
    Consider a finite, perfect information game with two players, where the only possible outcomes are a win for one of the players or a tie. 
    Then, exactly one of the following holds:
    \begin{enumerate}
        \item Player 1 has a winning strategy, no matter what Player 2 does.
        \item Player 2 has a winning strategy, no matter what Player 1 does.
    \end{enumerate}
\end{corollary}
\noindent Therefore, the possible solutions for a game are classified as follows:
\begin{itemize}
    \item \textit{Very weak solution}: the game has a rational outcome, but it is inaccessible.
    \item \textit{Weak solution}: the outcome of the game is known, but the method to achieve it is not.
    \item \textit{Solution}: there exists an algorithm that can determine the outcome.
\end{itemize}