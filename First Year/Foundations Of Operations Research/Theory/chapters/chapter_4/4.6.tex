\section{Sensitivity analysis}

The sensitivity analysis of a linear programming problem involves examining the impact of minor modifications to the problem's data on the optimal solution. 
It assesses the sensitivity of an optimal solution concerning variations in the model parameters.
\begin{definition}[\textit{Shadow price}]
    The shadow price associated with the $i$-th resource is the maximum price the company is willing to acquire an additional unit of the $i$-th resource.
\end{definition}

\subsection{Algebraic form}
Examine the sensitivity of an optimal solution concerning variations in the model parameters $\left\langle c_j, a_{ij}, b_i \right\rangle $.
Given the linear programming problem:
\begin{align*}
    \min                      \:&\: c^T            \\
    \textnormal{such that }     &\: Ax = b         \\
                                &\: x \geq 0
\end{align*}
And optimal basic solution $x^{*}$: 
\[x^{*}_B=B^{-1}b \geq 0\]
\[x^{*}_N=0\]
The objective is to assess the limits that maintain optimality for $B$ under two conditions:
\begin{enumerate}
  \item \textit{Feasibility}: $B^{-1} b \geq 0$.
  \item \textit{Optimality}: $c_N^T = c_N^T - c_B^T B^{-1} N = 0^T$.
\end{enumerate}

\paragraph*{Changes in the requirement vector b}
Consider a change in a component $b_i$ of the requirements vector $b$ by a small amount $\delta$.
The updated requirements vector is given by:
\[ b^T := b + \delta e_k \]
Here, $e_k$ is the unitary vector with a value of $1$ on the $k$-th position ($1 \leq k \leq n$) and $0$ elsewhere.
The goal is to determine the range of values for $\delta$ within which the current basis remains optimal. 
Since the optimality conditions are unaffected by the change, only the feasibility condition needs verification.
The basis $B$ with the basic solution: 
\[ x^{*} = \begin{bmatrix} B^{-1} b^T \\ 0 \end{bmatrix} = \begin{bmatrix} B^{-1} \left( b + \delta e_k \right) \\ 0 \end{bmatrix} \]
remains optimal as long as the following relation holds:
\[ B^{-1} \left( b + \delta e_k \right) \geq 0 \Rightarrow B^{-1} b \geq - \delta B^{-1} e_k \]
This results in $m$ inequalities defining an interval of values for $\delta$.
If $\delta$ falls outside this allowed range, the current solution satisfies the optimality conditions but is primal infeasible.
While the basis $B$ remains optimal, the optimal basic feasible solution $x^{*}$ changes.
The objective function value shifts from $c_B^T B^{-1} b$ to $c_B^T B^{-1} \left( b + \delta e_k \right)$. 
Consequently, the optimal value of the dual variable is given by:
\[ \Delta z^{*} = c_B^T B^{-1} \left( \delta e_k \right) = \delta  y_k^{*} = \delta  \dfrac{\partial z^{*}}{\partial b_k}\]
where $\Delta z^{*}$ represents the shadow price of the $k$-th resource.

\paragraph*{Changes in the cost vector c}
Consider a change in a cost coefficient $c_j$ of the objective function $c$ by a small amount $\delta$.
The updated cost vector is given by:
\[ c^T := c + \delta  e_j \]
Here, $e_j$ is the unitary vector with a value of $1$ on the $j$-th position ($1 \leq j \leq n$) and $0$ elsewhere.
The primal feasibility condition is unaffected, so the only condition to verify is the optimality condition:
\[ c^T_B B^{-1} A \leq c^T \]
Two cases then arise:
\begin{enumerate}
  \item $c_j$ is the cost of a basic variable: the optimal solution remains unchanged.
  \item $c_j$ is the cost of a non-basic variable: the optimal solution changes.
\end{enumerate}
However, the basic solution does not change:
\[ x_B^{*} = B^{-1} b \ \land x_N^{*} = 0 \]

\paragraph*{Cost associated with a non-basic variable}
If $c_j$ is the cost coefficient of a non-basic variable $x$, then $c_B$ is not affected, and the only inequality impacted is the one for the reduced cost of $x_j$:
\[ c^T_B B^{-1} A_j \leq c_j + \delta \]
This inequality establishes a lower bound for $\delta$:
\[ \delta \geq - c_j \]
If this condition is satisfied, the current basis is optimal.
The reduced cost represents the maximum decrease of $c_j$ for which $B$ remains optimal.

\paragraph*{Cost associated with a basic variable}
If $c_j$ is the cost coefficient of the $l$-th basic variable, then $c_B$ is affected by the change in $c_j$:
\[ c^T_B := c_B + \delta  e_l \]
All the optimality conditions are then affected by the change in $c_j$:
\[ \left( c_B + \delta e_l \right)^T B^{-1} A \leq c_i \quad \forall i \neq j \]
The variable $x_j$ is skipped as it is basic, and its reduced cost stays at zero. 
The condition is equal to:
\[ \delta_{q_{li}} \leq c_i \quad \forall i \neq j \]
Here, $q_{li}$  is the coefficient corresponding to the position of the $l$-th basic variable in the $i$-th row of $A$.
These inequalities determine the range of $\delta$ for which the same basis remains optimal.