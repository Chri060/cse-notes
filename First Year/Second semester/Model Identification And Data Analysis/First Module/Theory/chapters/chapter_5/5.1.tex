\section{Introduction}

Let's consider a process with a rational spectrum:
\[v(t)=W(z)\eta(t)=\dfrac{C(z)}{A(z)}\eta(t) \qquad \eta(\cdot)\sim WN(0,\lambda^2)\]
Prediction aims to estimate the future value $v(t+r)$ (with $r>0$) based on observations of the process up to time $t$.
This estimate, denoted as $\hat{v}(t+r|t)$, depends on the predictor horizon $r$. 
Generally, the predictor takes the form:
\[\hat{v}(t+r|t)=f\left( v(t),v(t-1),\dots \right)\]
It's important to note that the prediction error itself is a stochastic process since $\hat{v}(\cdot)$ depends on random variables.
\begin{example}
    A na√Øve predictor could be constructed by averaging the last observed samples:
    \[\hat{v}(t+1|t)=\dfrac{1}{3}v(t)+\dfrac{1}{3}v(t-1)+\dfrac{1}{3}v(t-2)\]
\end{example}
Our goal is to find the optimal predictor that effectively combines information from the model and the available past observations. 

\subsection{Prediction error}
To assess prediction quality, we define the prediction error (or residual) as:
\[\varepsilon(t+r)=v(t+r)-\hat{v}(t+r|t)\]
The optimal predictor minimizes the mean square prediction error (MSPE), which is the variance of the residual:
\[\min\left( \mathbb{E}\left[\varepsilon(t)^2 \right] \right)\]
Recalling the expansion of $W(z)$ in negative powers of $z$: 
\[W(z)=w_0+w_1z^{-1}+w_2z^{-2}+\dots\]
We can express $v(t)$ as an infinite linear combination of past noise values:
\[v(t)=w_0\eta(t)+w_1\eta(t-1)+w_2\eta(t-2)+\dots\]
Suppose the past of $\eta(\cdot)$ is measured. 
Then, we could use this information to estimate $v(t+r)$ for $r \geq 1$: 
\[v(t+r)=\underbrace{w_0\eta(t+r)+w_1\eta(t+r-1)+\dots+w_{r-1}\eta(t+1)}_{\alpha(t)} +\underbrace{w_r\eta(t)+w_{r+1}\eta(t-1)+\dots}_{\beta(t)} \]
Now, $\alpha(t)$ and $\beta(t)$ are uncorrelated random variables (they are linear combinations of the same white noise process over non-overlapping time ranges):
\begin{itemize}
    \item $\beta(t)$ can be computed once the past of $\eta(\cdot)$ (up to $t$) is known. 
    \item $\alpha(t)$ depends on the future of $\eta(\cdot)$ (from $t+1$ to $t+r$). 
\end{itemize}
Thus, $\alpha(t)$ exhibits no correlation with the past until time $t$, indicating its unpredictability based on past information. 
Consequently, we can solely estimate its mean, which is zero:
\[\mathbb{E}=w_0\mathbb{E}\left[\eta(t+r)\right]+w_1\mathbb{E}\left[\eta(t+r-1)\right]+\dots+w_{r-1}\mathbb{E}\left[\eta(t+1)\right]=0\]
This leads to the optimal predictor:
\[\hat{v}(t+r|t)=\beta(t)=w_r\eta(t)+w_{r+1}\eta(t-1)+\dots\]
The prediction error is then given by:
\[\varepsilon(t+r)=v(t+r)-\hat{v}(t+r|t)=\alpha(t)=w_0\eta(t+r-1)+\dots+w_{r-1}\eta(t+1)\]
It's notable that $\varepsilon(\cdot)$ represents a Moving Average (MA) process. 
Its mean value is 0, and its variance is $(w_0^2 + w_1^2 + \dots + w_{r-1}^2)\lambda^2$.

Moreover, the variance increases monotonically with $r$, signifying that prediction uncertainty escalates with the prediction horizon:
\begin{itemize}
    \item For $r=1$, the variance equals $w_0^2\lambda^2$. 
        When $w_0=1$ (if the function $W(z)$ is canonical), it aligns with the noise variance:
        \[\text{Var}\left[\varepsilon(t) \right]=\text{Var}\left[\eta(t) \right]\]
    \item As $r$ approaches infinity, the variance becomes $(w_0^2 + w_1^2 + \dots)\lambda^2$, equivalent to the variance of the entire process $v(t)$:
        \[\text{Var}\left[\varepsilon(t) \right]=\text{Var}\left[v(t) \right]\]
\end{itemize}
Indeed, prediction becomes progressively challenging with increasing $r$ since the estimation pertains to a distant time point beyond the available data. 
Over time, past data lose their utility, and the most reasonable estimate is the variable's mean: 
\[\mathbb{E}\left[v(t+r)\right]=0\]
Consequently, the variance of the prediction error approaches that of the process:
\[\text{Var}\left[\varepsilon(t)\right]=\mathbb{E}\left[\left(v(t+r)-\hat{v}(t+r|t)\right)^2\right]=\text{Var}\left[v(t)\right]\]
The optimal predictor can be expressed using operator notation:
\[\hat{v}(t+r|t)=\left[w_r+w_{r+1}z^{-1}+w_{r+2}z^{-2}+\dots \right]\eta(t)=\hat{W}_r(z)\eta(t)\]