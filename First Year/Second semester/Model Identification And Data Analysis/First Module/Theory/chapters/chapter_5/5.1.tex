\section{Estimation of mean and covariance function}

Let $v(t)$ represent a stationary stochastic process with unknown probabilistic properties, for which we have a finite realization $\left\{ v(1),v(2),\dots,v(n) \right\}$. 
Our objective is to estimate the probabilistic properties of $v(t)$ from this data:
\begin{itemize}
    \item \textit{Mean}: $\mu=\mathbb{E}\left[ v(t) \right]\rightarrow\widehat{\mu}=\widehat{\mu}_N\left( v(1),v(2),\dots,v(N) \right)$
    \item \textit{Autocovariance}: $\gamma(\tau)=\mathbb{E}\left[\left(v(t)-\mu\right)\left(v(t-\tau)-\mu\right)\right] \rightarrow \widehat{\gamma}(\tau)=\widehat{\gamma}_N\left(\tau;v(1),v(2),\dots,v(n)\right)$
\end{itemize}
The functions $\widehat{\mu}$ and $\widehat{\gamma}(\tau)$ are derived from the available data and are referred to as sample estimators.
Their primary objective is to provide estimates that closely match the underlying probabilistic properties being estimated, regardless of the specific data sequence available.

\subsection{Mean function}
A natural sample estimator for the mean is:
\[\widehat{\mu}_N=\dfrac{1}{N}\sum_{t=1}^Nv(t)\]
It's important to note that $\widehat{\mu}_N$ is a random variable because it depends on the realization of  $v(t)$. 
\begin{definition}[\textit{Unbiased estimator}]
    An estimator is unbiased if its expected value (taken over all possible finite realizations of $v(t)$) equals the property being estimated.
\end{definition}
For our estimator to be unbiased, we require $\mathbb{E}\left[ \widehat{\mu}_N \right]=\mu$. 
In our case:
\[\mathbb{E}\left[ \widehat{\mu}_N \right]=\mathbb{E}\left[ \dfrac{1}{N}\sum_{t=1}^Nv(t) \right]=\dfrac{1}{N}\sum_{t=1}^N\mathbb{E}\left[ v(t) \right]=\dfrac{1}{N}\sum_{t=1}^N \mu =\mu\]
Consider a fixed $s = \bar{s}$, where the process realization is constant over time:
\begin{itemize}
    \item $\widehat{\mu}_N=\dfrac{1}{N}\sum_{t=1}^Nv(t,\bar{s})=\dfrac{1}{N}\sum_{t=1}^Nv(\bar{s})=v(\bar{s})$
    \item $\mu=\mathbb{E}\left[v(t,s)\right]=\mathbb{E}\left[v(s)\right]=0$
\end{itemize}
While $\widehat{\mu}_N$  is unbiased, it may not provide a good estimate of the expected value of $v(t)$, even with infinite data.

We need another property to ensure a good estimate. 
\begin{definition}[\textit{Consistent estimator}]
    An estimator is consistent if the variance of its estimation error tends to zero as the data size tends to infinity:
    \[\mathbb{E}\left[\left(\widehat{\mu}_N-\mu\right)^2\right]\overset{N\rightarrow\infty}{\longrightarrow}0\]
\end{definition}
This property doesn't hold for all stationary processes. 
A good estimator satisfies both correctness and consistency.
\begin{example}
    Consider the constant process $v(t,s)=v(s)$, where $v(s) \sim N(0,1)$: 
    \[\mathbb{E}\left[\left(\widehat{\mu}_N-\mu\right)^2\right]=\mathbb{E}\left[\left(\dfrac{1}{N}\sum_{t=1}^{N}v(s)-0\right)^2\right]=\mathbb{E}\left[v(s)^2\right]=1\neq 0\]
\end{example}

For stationary ARMA processes, the mean estimator is consistent.

\subsection{Covariance function}
Let $v(t)$ be a stationary stochastic process with a zero mean. 
In this scenario:
\[\gamma(\tau)=\tilde{\gamma}(\tau)=\mathbb{E}\left[ v(t)v(t-\tau) \right]=\mathbb{E}\left[v(t)v(t+\tau)\right]\]
The sample estimator of $\gamma(\tau)$ is given by: 
\[\widehat{\gamma}_N(\tau)=\dfrac{1}{N-\tau}\sum_{t=1}^{N-\tau}v(t)v(t+\tau) \qquad 0 \leq \tau N-1\]
It's noteworthy that given $\left\{v(1), v(2), \dots, v(N)\right\}$, we have:
\begin{itemize}
    \item $\widehat{\gamma}_N(0)$ is computed from a sum of $N$ elements.
    \item $\widehat{\gamma}_N(1)$ is computed from a sum of $N-1$ elements.
    \item $\widehat{\gamma}_N(N-1)$ is computed from just one element.
\end{itemize}
The accuracy of $\widehat{\gamma}_N(\tau)$ decreases as $\tau$ (the approximation is reliable only for $\tau \ll N$).
The provided sample estimator $\widehat{\gamma}_N(\tau)$ is both correct and consistent for ARMA processes.

Another estimator of $\gamma(\tau)$ can be considered:
\[\widehat{\gamma}_N^{\prime}(\tau)=\dfrac{1}{N}\sum_{t=1}^{N-\tau}v(t)v(t+\tau) \qquad 0 \leq \tau N-1\]
This estimator is biased for finite $N$, but it becomes unbiased as $N\rightarrow\infty$ (asymptotically correct).
Only $\widehat{\gamma}_N^{\prime}(\tau)$ satisfies the positive semi-definiteness property of a covariance function.