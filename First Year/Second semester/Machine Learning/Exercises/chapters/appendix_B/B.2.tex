\section{Perceptron}

The perceptron operates as a discriminant function approach since it directly assigns elements into classes without providing probabilities.
\paragraph*{Functions definition}
To proceed with our analysis, we must define the following elements:
\begin{itemize}
    \item Hypothesis space: we consider linear models represented by:
        \[y(\textbf{x})=\text{sign}(\textbf{w}^T\textbf{x})=\text{sign}(w_0+x_1w_1+x_2w_2)\]
        Here, 
        \[\text{sign}(z)=\begin{cases}
            -1 \qquad\text{if }z<0 \\
            +1 \qquad\text{otherwise}
        \end{cases}\]
    \item Loss function: distance of misclassified points in $\{(\textbf{x}_n, t_n)\}^{N}_{n=1}$ with $t_n\in\{-1,1\}$: 
        \[L_P(\textbf{w})=-\sum_{n\in\mathcal{M}}\textbf{w}^T\textbf{x}_nt_n\]
        Here, $\mathcal{M}=\left\{ n\in\{1,\dots,N\}:t_n\neq y(\textbf{x}_n) \right\}$
    \item Optimization method: online gradient descent
\end{itemize}

\subsection{Result evaluation}
This method converges when the data are linearly separable. 
To visualize the separating hyperplane or decision boundary (line) we need to plot:
\[\text{sign}(\textbf{x}^T\textbf{x}) = 0 \rightarrow \text{sign}(w_0 + x_1w_1 + x_2w_2) = 0 \rightarrow x_2=-\dfrac{w_1x_1+w_0}{w_2}\]
To evaluate the performance of a classifier, we can to compute the confusion matrix which tells us the number of points which have been correctly classified and those which have been misclassified
\begin{table}[H]
    \centering
    \begin{tabular}{cccc}
                                                                   & \textit{}              & \multicolumn{2}{c}{\textit{Actual class}}            \\ \cline{3-4} 
    \textit{}                                                      & \multicolumn{1}{c|}{}  & 1              & \multicolumn{1}{c|}{0}              \\ \cline{2-4} 
    \multicolumn{1}{c|}{\multirow{2}{*}{\textit{Predicted class}}} & \multicolumn{1}{c|}{1} & True positive  & \multicolumn{1}{c|}{False positive} \\
    \multicolumn{1}{c|}{}                                          & \multicolumn{1}{c|}{0} & False negative & \multicolumn{1}{c|}{True negative}  \\ \cline{2-4} 
    \end{tabular}
\end{table}
From this table we can compute the following measures: 
\begin{itemize}
    \item Accuracy: fraction of the samples correctly classified in the dataset: 
        \[\text{Acc}=\dfrac{TP+TN}{N}\]
    \item Precision: fraction of samples correctly classified in the positive class among the ones classified in the positive class: 
        \[\text{Pre}=\dfrac{TP}{TP+FP}\]
    \item Recall: fraction of samples correctly classified in the positive class among the ones belonging to the positive class: 
        \[\text{Rec}=\dfrac{TP}{TP+FN}\]
    \item F1 score: harmonic mean of the precision and recall: 
        \[\text{F1}=\dfrac{2\cdot\text{Pre}\cdot\text{Rec}}{\text{Pre}+\text{Rec}}\]
\end{itemize}
The higher these figures of merits the better the algorithm is performing.
These performance measures are not symmetric, but depend on the class we selected as positive.
Depending on the application one might switch the classes to have measures which better evaluate the predictive power of the classifier.

\subsection{Python implementation}
Implementation in Python can be accomplished either through the \texttt{sklearn} library utilizing the \texttt{Perceptron} module, or by manually coding the algorithm.