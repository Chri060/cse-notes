\section{Model definition}

When a model consistently performs poorly even after thorough parameter tuning and cross-validation, there are two opposite strategies to consider: simplifying the model or increasing its complexity.
To simplify a model, several techniques can be employed:
\begin{itemize}
    \item \textit{Feature selection}: this involves choosing only a subset of significant features to use in the model, discarding irrelevant or redundant ones.
        We use: filter methods, embedded methods or wrapper methods such as backward step-wise selection. 
    \item Feature extraction: by projecting the features into another, typically lower-dimensional space, techniques like Principal Component Analysis (PCA) or t-SNE can reduce the complexity of the data while preserving its important characteristics.
    \item Regularization (shrinkage): Regularization techniques, such as Lasso and Ridge regularization, introduce penalties for complex models in the loss function, discouraging overly complex models and mitigating overfitting.
\end{itemize}
Ensembling methods involve combining multiple models to improve predictive performance. Two common ensembling techniques are: bagging and boosting. 





