\section{Introduction}

When faced with persistent poor performance of a model despite exhaustive parameter tuning and cross-validation, two opposing strategies emerge: simplification or augmentation of complexity.
To simplify a model, various techniques can be employed:
\begin{itemize}
    \item \textit{Feature selection}: this process entails selecting a subset of significant features while discarding irrelevant or redundant ones. 
        Techniques such as filter methods, embedded methods, or wrapper methods like backward step-wise selection can be utilized.
    \item \textit{Feature extraction}: by transforming features into another space, often of lower dimensionality, techniques such as Principal Component Analysis (PCA) or t-SNE can reduce data complexity while retaining essential characteristics.
    \item \textit{Regularization} (shrinkage): techniques like Lasso and Ridge regularization introduce penalties for complex models within the loss function, discouraging overfitting and promoting simpler models.
\end{itemize}