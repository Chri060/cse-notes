\section{Exercise two}

We determine the regression coefficients in a linear regression model by minimizing ridge regression for a specific value of $\lambda$. 
For each of the following, elucidate the trend of the elements as we increment $\lambda$ from $0$ (e.g., remains constant, increases, decreases, increases and then decreases):
\begin{enumerate}
    \item The training RSS. 
    \item The test RSS. 
    \item The variance. 
    \item The squared bias. 
    \item The irreducible error. 
\end{enumerate}

\subsection*{Solution}
\begin{enumerate}
    \item Increases: as $\lambda$ increases, simpler models are favored, leading to a decrease in flexibility and an inability to fit the training data precisely. 
        Consequently, the training RSS will steadily increase.
    \item Decreases and then increases. 
        Initially, as $\lambda$ increases, the test RSS improves due to a reduction in overfitting on the training data. 
        However, beyond a certain point, overly simplistic models fail to capture the true underlying patterns, causing the test RSS to increase.
    \item Decreases: increasing $\lambda$ forces the use of simpler models, which inherently reduces the variability of the fits across different datasets.
    \item Increases: with higher $\lambda$ values, simpler models are employed, likely resulting in larger squared bias as these models may fail to capture the true underlying relationships adequately.
    \item Remains constant: increasing $\lambda$ does not affect the irreducible error since it is independent of the model's complexity and solely depends on the inherent noise in the data.
\end{enumerate}