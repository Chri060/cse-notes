\section{Exercise three}

What methods would you employ to assess the efficacy of various models given the following scenarios:
\begin{enumerate}
    \item Limited dataset size with straightforward models.
    \item Limited dataset size with intricate models.
    \item Extensive dataset with basic models.
    \item Extensive dataset with access to parallel computing capabilities for training.
\end{enumerate}
Justify you choices.

\subsection*{Solution}
\begin{enumerate}
    \item Leave-one-out cross-validation (LOO): when dealing with a small dataset and simple models, LOO is a viable option as it doesn't pose significant computational complexity. 
        This method offers a nearly unbiased estimation of the test error.
    \item Akaike information criterion (AIC) with Adjustment Techniques: with a smaller dataset, training might lead to overfitting, rendering traditional methods ineffective. 
        AIC, with its adjustment techniques, can help mitigate overfitting concerns. 
        However, for complex models, LOO may still be impractical due to computational constraints.
    \item Cross-validation (CV): cross-validation is suitable for obtaining stable estimates to select the best model, particularly when Leave-One-Out is infeasible due to computational complexity. 
        It balances the need for reliable estimates with computational efficiency.
    \item Parallelized leave-one-out (LOO): in scenarios where parallel computing resources are available, and a large dataset is being utilized, parallelizing LOO can significantly reduce computation time.
        By concurrently training multiple models, the time required for LOO can be reduced by a factor equal to the number of parallel processes running simultaneously.
\end{enumerate}