\section{Textures}

Defining the appearance of realistic 3D objects requires meticulous detail, especially considering the varying material specifications across the surface. 
However, assigning distinct materials to numerous small triangles is impractical due to memory constraints. 
A common approach involves using tables to adjust shader parameters based on the surface's internal points. 
These tables, often referred to as textures or maps, contain not only the diffuse color obtained from images but also other properties to parameterize the Bidirectional Reflectance Distribution Function (BRDF) of a surface.

Textures come in various forms:
\begin{itemize}
    \item \textit{2D textures}: these define surface parameters for objects.
    \item \textit{3D textures}: they extend to defining parameters within volumes.
    \item \textit{1D textures}: these hold pre-computed function values or serve optimization purposes.
    \item \textit{Cube maps textures}: used for defining parameters associated with directions in a 3D coordinate system, using a slightly different approach.
\end{itemize}
While images defining object surfaces are planar, the objects they are applied to exhibit complex non-planar 3D topologies with multiple sides. 
When applying 2D textures to 3D objects, a mapping relation is established, associating each surface point with a point on the texture. 
This mapping creates a correspondence between object points and texture pixels (texels). 
However, achieving a mapping that utilizes the entire texture space is challenging, often leaving some areas unused.

For meshes, the mapping procedure establishes a correspondence between surface triangles and corresponding triangles on the texture.

\subsection{UV coordinates}
Points on 2D textures are addressed using a Cartesian coordinate system, typically denoted by axes labeled $u$ and $v$. 
This coordinate system is commonly referred to as UV, mapping, or texture coordinates. 
In this convention, the $u$ and $v$ values range between 0 and 1 along the horizontal and vertical axes of the texture, respectively.

UV coordinates are assigned exclusively to the vertices of triangles, adding two additional parameters to their positions (and often to the direction of the normal vector). 
For internal points, UV coordinates are computed through interpolation, using techniques similar to those employed for normal vector directions.

Properly assigning UV coordinates to the model is a crucial but complex and often tedious task performed by 3D artists and modelers. 
It's worth noting that UV mapping does not necessarily need to be a bijection; the same part of the texture can be shared by several triangles on the 3D object. 
Skilled 3D artists can leverage this feature to enhance the quality of their models.

It's important to recognize that, similar to normal vector directions, two vertices belonging to different triangles may occupy the same position in space but have different UV coordinates.

\paragraph*{UV intervals}
In many scenarios, the $u$ or $v$ values may extend beyond the $[0, 1]$ range. 
This occurrence can be interpreted in various ways, each of which can affect the final texture sampling differently. 
The four most common approaches for managing values that are negative or greater than one are:
\begin{itemize}
    \item \textit{Clamp}: extends the colors of the border to the texels that lie outside the $[0, 1]$ range.
    \item \textit{Repeat}: utilizes only the fractional part of the UV coordinates, discarding their integer part, thus repeating the pattern.
    \item \textit{Mirror}: repeats the texture pattern similar to the repeat strategy but flips it at each repetition.
    \item \textit{Constant}: replaces the texture samples falling outside the $[0, 1]$ range with a default color $c_d$.
\end{itemize}
By employing various combinations of strategies for the $u$ and $v$ directions, numerous effects can be achieved.

\subsection{Rasterization with textures}
The initial step in supporting textures involves interpolating the UV coordinates alongside other vertex parameters, such as normal vectors.
Subsequently, a lookup procedure is employed to retrieve the corresponding texel from the texture. 
Finally, a per-pixel operation is executed to calculate the rendering equation for each pixel on the screen.

\paragraph*{Perspective interpolation}
When perspective is utilized, conventional interpolation methods are inadequate due to the non-linearity of the projection. 
Applying traditional interpolation techniques to compute internal parameter values associated with triangles under perspective can result in apparent wobbling of straight lines, as depicted in the image below.

To mitigate such wobbling artifacts, applications adopt perspective-correct interpolation. 
This technique involves non-linear interpolation, where the interpolation behavior depends on the distance of the interpolated points from the projection plane.

\subsection{Cube map textures}
Cube-map textures consist of collections of six images, each corresponding to one of the six sides of a cube. 
These textures are indexed by a direction vector, specified with its $x$, $y$, and $z$ components. 
The components of the normal vector determine both the side of the cube (the base image) and the corresponding texel on that image.

In modern applications, cube map textures play a crucial role as they serve as building blocks for creating realistic rendering effects that emulate mirror reflection and transparency. 
Additionally, they are utilized to store image-based ambient lighting parameters.

\subsection{Texture filtering}
UV coordinates are represented as floating-point numbers, whereas texels are indexed by integer values. 
Additionally, the shape of a pixel on the screen may correspond to a complex polygon composed of several texels on the texture. 
To address these challenges, a set of techniques collectively known as filtering is employed.

When a texel is larger than the corresponding pixel on the screen, a magnification filtering problem arises. 
Conversely, when the pixel on the screen corresponds to multiple texels, a minification filtering problem occurs. 
The latter case is notably more challenging than the former.

\paragraph*{Magnification filters}
Two magnification filters are typically defined:
\begin{itemize}
    \item \textit{Nearest pixel}: in this approach, the lookup procedure transforms the UV coordinates with respect to the texture size and returns the texel $p[i][j]$, considering only the integer part of the scaled coordinates. 
        This method is fast, requiring just one texel read per pixel. 
        However, it tends to produce blocky images.
        \[x=u\cdot w \qquad i=\left\lfloor x \right\rfloor\]
        \[y=v\cdot h \qquad j=\left\lfloor y \right\rfloor\]
    \item \textit{Bilinear interpolation}: linear interpolation calculates the pixel color by interpolating from the values of its closest neighbors. 
        While this technique produces smoother results, it necessitates four texture accesses and three interpolations.
        Although the term bilinear interpolation is commonly used, it's more appropriately described as linear interpolation. 
        For 1D textures, interpolation occurs over one axis (involving 2 texels and 1 interpolation), while for 3D textures, it spans three dimensions (involving 8 texels and 7 interpolations). 
        This interpolation becomes even more intricate in cube maps, especially for pixels along the borders or at the corners.
\end{itemize}

\paragraph*{Minification filters}
The most commonly used minification filters include:
\begin{itemize}
    \item \textit{Nearest pixel}. 
    \item \textit{Bilinear interpolation}.
    \item \textit{Mip-mapping}: this approach pre-computes a series of scaled versions of the texture (called levels), each with halved size. 
        Each pixel in the inner level of a Mip-map corresponds to the average of a set of pixels in the original image. 
        Depending on the texture-to-pixel ratio, the algorithm selects the closest image in the Mip-map, providing smoother results compared to basic interpolation.
    \item \textit{Trilinear interpolation}: when images are angled with respect to the viewer, there may be a change of level within the mapping of a single figure. 
        Trilinear filtering computes the required pixel twice, using the two closest levels of the Mip-map, and then interpolates between them for a smooth transition.
    \item \textit{Rip-mapping}: a Rip-map encodes rectangular scaling of the original texture, addressing the blurring issue that occurs with traditional Mip-maps when surfaces are angled with respect to the viewer. 
        However, this technique is rarely implemented due to its large memory requirements and inability to deal with angled triangles effectively.
    \item \textit{Anisotropic}: when surfaces are angled with respect to the screen border, the pixel on the screen corresponds to a non-square and non-rectangular trapezoid over the texture. 
        To address this issue, the Anisotropic Unconstrained Filter offers a solution.
        This algorithm approximates the precise area of texels corresponding to a pixel on the screen. 
        It leverages Mip-maps and samples one of its levels following the direction of the pixel over the texels. 
        Initially, the algorithm identifies the texture position of the four borders of the pixel. 
        Subsequently, based on the size of the smallest side of the trapezoid, it determines the most suitable Mip-map level (one with a similar pixel-to-texel ratio). Then, it samples the selected Mip-map level along a line in the direction of the on-screen pixel. 
        Typically, the number of samples is capped at a maximum value, often set to 8 or 16.
        While highly effective, this method incurs a significant overhead that may slow down rendering.
        Vulkan supports enabling Anisotropic filtering if it's supported by the graphics adapter.
\end{itemize}
Nearest pixel and bilinear interpolation behave similarly to magnification filters, but they yield poor results when the reduction is substantial. 
Minification should ideally average the texels falling inside a pixel rather than merely guessing an intermediate value.