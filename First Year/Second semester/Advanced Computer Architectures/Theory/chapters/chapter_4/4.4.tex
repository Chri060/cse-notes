\section{Scheduling}

Two essential properties must be maintained to ensure program correctness, typically achieved by preserving both data and control dependencies. 
The first is exception behavior, which ensures that any changes in the execution order of instructions do not affect how exceptions are triggered within the program. 
The second is data flow, which pertains to the actual movement of data values among instructions, ensuring that the correct results are produced and consumed.

There are two main strategies to support ILP: dynamic scheduling and static scheduling. 
Dynamic scheduling relies on hardware to identify and exploit parallelism within the program, while static scheduling depends on software to identify potential parallelism beforehand. 

\subsection{Dynamic scheduling}
Dynamic scheduling involves hardware reordering instruction execution to mitigate pipeline stalls while upholding data flow and exception behavior. 
The main advantages of this approach include handling cases where dependencies are unknown at compile time, simplifying compiler complexity, and facilitating efficient execution of compiled code on different pipeline architectures. 
However, these benefits come with costs such as a significant increase in hardware complexity, higher power consumption, and the potential for imprecise exceptions. 
In dynamic scheduling, instructions are fetched and issued in program order, but execution begins as soon as operands are available, potentially allowing out-of-order execution. 
This introduces the possibility of WAR and WAW data hazards and implies out-of-order completion unless a reorder buffer is present to ensure in-order completion.

\subsection{Static scheduling}
In static scheduling, compilers use sophisticated algorithms for code scheduling to harness ILP. 
While the ILP available within a basic block is often limited, significant performance improvements can be achieved by exploiting ILP across multiple basic blocks, transcending branches. 
Static scheduling involves the compiler detecting and resolving dependencies by reordering code to avoid conflicts. 
The compiler's output is typically dependency-free code, which is well-suited for architectures like Very Long Instruction Word (VLIW) processors. 
However, there are limits to ILP exploitation, including unpredictable branches, variable memory latency such as unpredictable cache misses, code size explosion, and increased compiler complexity.