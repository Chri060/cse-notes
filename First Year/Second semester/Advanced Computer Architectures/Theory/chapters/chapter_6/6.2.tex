\section{Thread-level parallelism}

Improving the performance and clock frequency of a single core has become increasingly challenging due to several factors:
\begin{itemize}
    \item \textit{Heat dissipation}: managing the heat generated by high-frequency operations is problematic.
    \item \textit{Speed of light limitations}: physical limits on light speed affect transmission speeds in wires.
    \item \textit{Design complexity}: designing and verifying deep pipelines is complex and requires large design teams.
    \item \textit{Multithreaded applications}: many modern applications inherently support multithreading, demanding better support for parallel execution.
\end{itemize}
ILP architectures like superscalar and VLIW are designed to exploit fine-grained ILP but are not well-suited for supporting large-scale parallel systems. 
CPUs that attempt to issue multiple instructions per cycle have become exceedingly complex, with diminishing returns in extracting additional parallelism. 
As a result, extracting parallelism at higher levels has become more attractive.

To achieve higher performance, the next step involves process- and thread-level parallel architectures. 
This approach connects multiple microprocessors within a complex system to efficiently handle large-scale parallel tasks.
\begin{definition}[\textit{Parallel architecture}]
    A parallel computer is a collection of processing elements that cooperate and communicate to solve large problems quickly.
\end{definition}
The focus shifts from designing faster single processors to replicating processors to enhance performance. 
Parallel architecture extends traditional computer architecture by incorporating a communication framework that includes:
\begin{itemize}
    \item \textit{Abstractions}: defining the hardware and software interfaces.
    \item \textit{Efficient structures}: developing various structures to efficiently realize these abstractions.
\end{itemize}
By leveraging parallel architectures, systems can better support multithreaded applications and efficiently handle large-scale computational tasks, overcoming the limitations of ILP and deep pipeline designs.

\subsection{Vector processing}
Vector processors are specialized for performing high-level operations on linear arrays of numbers, known as vectors. 
A typical vector processor comprises a pipelined scalar unit (which may be out-of-order or VLIW) alongside a dedicated vector unit. 
There are two primary types of vector processors:
\begin{itemize}
    \item \textit{Memory memory vector processors}: all vector operations involve memory-to-memory transfers.
    \item \textit{Vector register processors}: vector operations occur primarily between vector registers, except for load and store operations. 
        This type is analogous to load-store architectures.
\end{itemize}
Vector processors excel in multimedia processing tasks such as compression, graphics, audio synthesis, and image processing.