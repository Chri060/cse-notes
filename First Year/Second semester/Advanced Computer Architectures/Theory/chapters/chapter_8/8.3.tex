\section{Trace Scheduling}

Trace scheduling focuses on optimizing sequences of instructions known as traces within a control flow graph. 
A trace, defined as a loop-free sequence of basic blocks, represents an execution path for a given set of inputs (Fisher). 
The likelihood of a trace being executed depends on the input set, with some traces being executed more frequently than others.

The process of trace scheduling begins with selecting a sequence of basic blocks that represents the most frequent branch path. 
Profiling feedback or compiler heuristics are used to identify these common paths. 
Once identified, the entire trace is scheduled at once, with fix-up code added to handle branches that jump out of the trace.

One limitation of trace scheduling is that it cannot extend beyond a loop barrier. 
This is typically addressed through loop unrolling, which allows scheduling to proceed beyond loops but can result in increased code size and performance degradation due to the costs of starting and ending iterations.

Despite these drawbacks, trace scheduling offers significant advantages by prioritizing the scheduling of traces based on their execution probability.
This ensures that the most frequently executed traces receive the best optimization. 
Traces are treated as basic blocks during scheduling, without special handling for branches.

A trace is a sequence of instructions that may include branches but does not include loops. 
The objective of trace scheduling is to identify common paths and schedule the traces within those paths independently. 
Scheduling within a trace relies on basic code motion, extending globally across multiple basic blocks through appropriate renaming.

Compensation codes are necessary for handling side entry points (points within the trace except the beginning) and side exit points (points within the trace except the end). 
However, blocks on non-common paths may incur additional overhead, necessitating a high probability of following the common path based on profiling data. 
Generating compensation codes, especially for entry points, can be particularly challenging.

\subsection{Code Motion}
In addition to the need for compensation codes, there are restrictions on code movement within a trace. 
The dataflow of the program must remain unchanged, and exception behavior must be preserved. 
Dataflow integrity is maintained by ensuring two types of dependencies: data dependency and control dependency.

To eliminate control dependency, two solutions are typically employed: using predicate instructions (Hyper-block scheduling) to remove the branch, or using speculative instructions (Speculative Scheduling) to move an instruction before the branch speculatively. 
These techniques allow for greater flexibility and efficiency in scheduling traces.