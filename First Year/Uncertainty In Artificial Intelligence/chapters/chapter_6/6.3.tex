\section{Inference}

Inference in a Bayesian network exhibits exponential complexity, typically on the order of $O(\left\lvert X_i \right\rvert^N)$, where $\left\lvert X_i \right\rvert$ represents the cardinality of the variables involved. 
To mitigate this computational complexity, several techniques can be applied:

\begin{itemize}
    \item Variable elimination: this method involves systematically eliminating variables to simplify the calculation of probabilities and reduce computational complexity.
    \item Belief propagation: by passing messages between nodes in the network, this technique efficiently computes marginal probabilities and updates beliefs, helping to alleviate the computational burden.
    \item Junction trees: these data structures are used to represent Bayesian networks, and they facilitate efficient computations for probabilistic inference. 
        The process of building junction trees can significantly reduce complexity.
    \item Loopy belief propagation: in situations where the network contains loops or cycles, loopy belief propagation can be employed to approximate inferences by iteratively updating beliefs.
    \item Sampling based methods: these methods rely on random sampling to estimate probabilities and make inferences. 
        They can be effective for handling complex Bayesian networks when exact methods become impractical.
\end{itemize}
It's worth noting that the first three methods, namely variable elimination, belief propagation, and junction trees, are exact methods that provide precise solutions, while the last two, sampling-based methods and loopy belief propagation, are approximate techniques used when obtaining an exact solution is challenging due to computational constraints.