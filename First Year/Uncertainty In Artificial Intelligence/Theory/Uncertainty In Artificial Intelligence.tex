\documentclass[12pt, a4paper]{report}
\usepackage{graphicx}
\usepackage[english]{babel}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{float}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{remark}
\newtheorem*{remark}{Definition}
\theoremstyle{definition}
\newtheorem{example}{Example}

\title{Uncertainty In Artificial Intelligence\\ \textit{Theory}}
\author{Christian Rossi}
\date{Academic Year 2023-2024}

\begin{document}

\maketitle

\newpage

\begin{abstract}
    The topics of the course are:
    \begin{itemize}
        \item Uncertainty sources that acffect models: typology, issues, and modeling approaches.
        \item Measure-based uncertainty modeling.
        \item Logic-based uncertainty modeling.
        \item Fuzzy models: fuzzy sets, fuzzy logic, fuzzy rules, motivations for fuzzy modeling, tools for fuzzy systems, design 
            of fuzzy systems, applications.
        \item Bayesian networks: basics, design, learning, evaluation, applications.
        \item Hidden Markov Models: basics, design, learning, evaluation, applications.
        \item Applications: motivations, choices, models, case studies.
    \end{itemize}
    \end{abstract}

\newpage

\tableofcontents

\newpage

\chapter{Introduction}
    \section{Definition}
    \begin{remark}
        \emph{Uncertainty} refers to epistemic situations involving imperfect or unknown information. It applies to predictions 
        of future events, to physical measurements that are already made, or to the unknown. 
    \end{remark}
    Uncertainty arises in partially observable or stochastic environments, as well as due to ignorance, indolence, or both. It arises 
    in any number of fields, including insurance, philosophy, physics, statistics, economics, finance, medicine, psychology, sociology, 
    engineering, metrology, meteorology, ecology and information science.
    
    The lack of certainty, a state of limited knowledge where it is impossible to exactly describe the existing state, a future outcome,
    or more than one possible outcome. This puts in evidence that uncertainty is related to the need of describing a piece of reality.

    \section{Modelling}
    Modelling is at the base of our life: the way we interact with the world is through models that interpret data coming from sensors
    and generate knowledge and actions. Modelling is also the way we may represent entities in a computer and possibly making it reasoning
    on them.
    \begin{remark}
        A \emph{model} is a representation of some entity, defined for a specific purpose. A model captures only the aspects of the entity
        modelled that are relevant for the purpose. A model is necessarily different from the modelled entity. So, intrinsic to modelling
        are all sort of uncertainities.
    \end{remark}
    All Artificial Intelligence applications are based on models, either defined by somebody or learned. Thes models are represented In
    different ways, but share uncertainty issue mainly on inputs. 

    \section{Uncertainty classification}
    The uncertainty can be of two main types: 
    \begin{itemize}
        \item Epistemic uncertainty: it is due to things one could in principle know but does not in practice. This may because a 
            measurement is not accurte, because the model neglets certain effects, or because particular data have been deliberately
            hidde. It is also known as systematic uncertainty and can in principle be reduced by enriching the model.      
        \item Aleatoric uncertainty: it is representative of unknown unknowns that differ each time we run the same experiment. 
            Aleatoric uncertainty is also known as statistical uncertainty, since only statistical information can describe it. This may
            also depend on the way we get and elaborate data. In general it is present when the model is missing some aspects.
    \end{itemize}
    The sources of uncertainty can be: 
    \begin{itemize}
        \item Parameter: it comes from the model parameters, whose esact values are unkonwn to experimentalists and cannot be controlled
            in experiments, or whose values cannot be inferred by statistical methods. 
        \item Parametric variability: it comes from the variability of input variables of the model. 
        \item Structural: also known as model inadequacy, model bias, or model discrepancy, this comes from the lack of knowledge of the
            problem.
        \item Algorithmic: also known as numerical uncertainty, or discrete uncertainty. This type comes from numerical errors and
            numerical approximations in the implementation of the computer model. 
        \item Experimental: also known as observation error, this comes from the variability of experimental measurements.
        \item Interpolation: this comes from a lack of variable data collected from computer model simulations and/or experimental 
            measurements. 
    \end{itemize}

    \section{Uncertainty modelling}
    The type of uncertainty model depends on the type of uncertainty, its sources and the information we have in uncertainty and mostly
    has to do with qualification and quantification of uncertainty. The possible model for uncertainty are: statistical, logical and
    cognitive.

    Artificial Intelligence and Machine Learning technlogies are based on models that include uncertainty models of these sorts, essential
    not only for the implementation of effective models, but also to define learning models able to cope with complex situations, and 
    to evaluate the quality of learned/developed models. 
    There are two major types of problems in uncertainty quantifiaction: 
    \begin{itemize}
        \item Forward propagation of uncertainty: the various sources of uncertainty are propagated through the model to predict the overall
            uncertainty in the system response:
            \begin{itemize}
                \item To evaluate low-order moments of the outputs (mean and variance).
                \item To evaluate the reliability of the outputs.
                \item To assess the complete probability distribution of the outputs. 
            \end{itemize}
            This is what is done also in Bayesian Networks and Graphical models. 
        \item Inverse assessment of model uncertainty and parameter uncertainty, where the model parameters are calibrated simultaneously
            using test data: given some experimental measurements of a system and some results from ist mathematical model, inverse 
            uncertainty quantifiaction estimates the discrepancy between the experiment and the mathematical model (bias correction) and
            estimates the values of unknown parameters un the model if there are any (parameter calibration).
    \end{itemize}
    The models used in Artificial Intelligence can be classified in three main types: 
    \begin{itemize}
        \item Symbolic models: elements of the models are expressed as terms related to entities to be modelled. The state of the world is
            represented by facts expressed in formal languages close to natural languages.
        \item Sub-symbolic models: elements of the models are expressed by code. 
        \item Black-box models: the model can be computed and possibly investigated, but it is only regarded as a computational way to map
            inputs to outputs. 
    \end{itemize}
    For symbolic models a fact is true in a model if it is possible to collect enough evidence to support it. the only really true facts 
    are the ones true by definition. All the others may be supported by evidence. 
    
    \section{Ignorance management}
    There are many potential sources of ignorance when reasoning in the real world:
    \begin{itemize}
        \item Insufficient data.
        \item Biased data: data are collected by sensors affected by errors. 
        \item Variable data: data are collected by imprecise sensors.
        \item Reliability of data. 
        \item Fuzzyness. 
        \item Reliability of the model: depends on the model design, implementation and parametrization. 
        \item Incompleteness of the model. 
    \end{itemize}
    \begin{example}
        Let’s consider the sentence "The elephant weighs 2 tons”. This can be interpret in various ways, each slightly different:
        \begin{itemize}
            \item The elephant weighs exactly 2 tons.
            \item The elephant weighs 2 tons ± 10 kg , given the resolution of the weight scales of the instrument.
            \item The elephant weighs approximately 2 tons, but we cannot say anything more precise.
            \item We are not sure about any previuos sentence be cause we do not have enough evidence.
        \end{itemize}
    \end{example}
    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{images/smithson.png}
        \caption{Smithson's taxonomy of ignorance and uncertainty}
    \end{figure}
    To model ignoranche most often it is decided to associate measures of some aspects. Let's distinguish between two aspects: 
    \begin{itemize}
        \item The type of representation: numbers, labels, intervals, \dots
        \item The represented ignorance thet we would like to model: i.e, probability, reliability, subjective evaluation, \dots
    \end{itemize}

    The probability is represented with numbers between zero and one, and a well-established set of rules and properties are associated 
    to its management, among which, given a set of alternative hypotesis: 
    \begin{itemize}
        \item The sum of their probabilities should be one. 
        \item The probability a posteriori of a hypotesis $h_i$ given some evidence $e$ si given by the Bayes theorem:
            \[P(h_i \mid e)=\frac{P(e \mid h_i)P(h_i)}{P(e)}\]
    \end{itemize}
    Probability was used, for example, in the MYCIN that was one of the first expert systems, aimed at diagnosing blood illness. They 
    modeled certainty by considering two numerical factors: 
    \begin{itemize}
        \item Measure of increased Belief: $MB=\frac{P(\frac{h}{e})-P(h)}{1-P(h)}$.
        \item Measure of decreased Disbelief: $MD=\frac{P(h)-P(\frac{h}{e})}{P(h)}$.
    \end{itemize}
    The measure of a statement is given by the certain factor:
    \[CF=MB-MD \in [-1;1]\]
    The main hypotesis for this solution is that the number given as $MB$ and $MD$ are not statistical probabilities, but subjective
    probabilities, provided by different experts and combined by rules (this may be ambiguous). 

    Compared to probabilities, linguistic terms are less ambiguous than numbers. Unsing a limited set of labels it is possible to associate
    to statements subjective evalutations, on which it is relatively easy to make subjective judgements converge. Then, a computational 
    mechanism is needed to define how to combine labels. This is done by using fuzzy systems, that are a representation of truth  of a 
    statement in linguistic terms, as evaluation of its fuzzyness. 

    \newpage

    \chapter{Fuzzy sets}
    \section{History}
    Fuzzy sets have been defined by Lotfi Zadeh in 1965 as a tool to model approximate concepts. In 1972 the first linguistic fuzzy
    controllers has been implemented. Around 1980 the fuzzy were used frequently worldwide. In the Nineties there were a massive 
    diffusion of fuzzy controllers in various end-user goods. Today, fuzzy systems are the kernel of many intelligent devices. 

    \section{Fuzzy membership function}
    A "crisp" set is defined by a boolean membership function on some property on the considered elements. Instead, a "fuzzy" set is
    a set whose membership function that ranges in the values between zero and one.
    \begin{remark}
        A \emph{membership function} defines a set, by defining the degree of membership of an element of the universe of discourse 
        to the set. A name is given to the set to make it possible to refer to it: this is usually called \emph{label}. Fuzzy sets can 
        also be defined with a variable with discrete values. 
    \end{remark}
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.50\linewidth]{images/function.png}
        \caption{Example of a membership function}
    \end{figure}
    To define a membership function we have to (according to the purpose of the model and the available data):
    \begin{enumerate}
        \item Select a variable on which the memebership function will be defined. 
        \item Define the range of the variable.
        \item Identify the fuzzy sets needed for the application and define the labels. 
        \item For each fuzzy set identify characteristic points for the membership function.
        \item Define the shape of the membership function.
        \item Check if the membership function is correct.
    \end{enumerate}
    The shapes of the membership function can be chosen arbitrarly. The choice of the shape modify the smoothness of the transition 
    between two labels (i.e., in intervals (orizontal shape) the transition is immediate). 
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.75\linewidth]{images/shape.png}
        \caption{Possible shapes for a membership function}
    \end{figure}
    \begin{remark}
        A set of fuzzy sets fully covering the universe of discourse is called \emph{frame of cognition}. The properties of this set are:
        \begin{itemize}
            \item Coverage: each element of the universe of discourse us assigned to at least one granule with membership greater or equal 
                than zero.
            \item Unimodality of fuzzy sets: there is a unique set of values for each granule with maximum membership. 
        \end{itemize}
    \end{remark}
    \begin{remark}
        A frame of cognition for which the sum  of the membership values of each value of the base variable is equal to one is called 
        a \emph{fuzzy partition}. 
    \end{remark}
    \begin{remark}
        The \emph{$\alpha$-cut} of a fuzzy set is the "crisp" set of the values of $x$ such that $\mu(x) \geq \alpha$:
        \[\alpha_\mu(x)=\{x \mid \mu(x) \geq \alpha\}\]
    \end{remark}
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.5\linewidth]{images/alpha.png}
        \caption{Alpha-cut of a membership function}
    \end{figure}
    \begin{remark}[H]
        The \emph{support} of a fuzzy set is the "crisp" set of values $x$ such that $\mu_f(x)>0$ is the \emph{support} of the fuzzy set
        $f$ on the universe $X$.
    \end{remark}
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.5\linewidth]{images/support.png}
        \caption{Support of a membership function}
    \end{figure}
    \begin{remark}
        The height $h_f$ of a fuzzy set $f$ on the universe $X$ is the highest membership degree of an element of $X$ to the fuzzy set:
        \[h_f(X)=\max_{x \in X}\mu_f(x)\]
        A fuzzy set is normal if, and only if, $h_f(X)=1$.
    \end{remark}
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.5\linewidth]{images/height.png}
        \caption{Height of a memebership function}
    \end{figure}








    \begin{remark}
        A fuzzy set is \emph{convex} if and oly if 
        \[\mu[\lambda x_1+(1-\lambda)x_2] \geq \min [\mu(x_1),\mu(x_2)]\]
        for any $(x_1,x_2) \in \mathbb{R}$ and any $\lambda \in [0,1]$.
    \end{remark}
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.75\linewidth]{images/convex.png}
        \caption{Graphical difference between a convex and a not convex set}
    \end{figure}
    The particular fuzzy sets are: signleton (a fuzzy set with exactly one member) and interval ( a fuzzy set whose members have all membership
    equals to one). The possible operations on the fuzzy sets are: 
    \begin{itemize}
        \item Complement: $\mu_{\bar{f}}(x)=1-\mu_f(x)$.
        \item Union: $\mu_{f_1 \cup f_2}(x)=\max [\mu_{f_1}(x),\mu_{f_2}(x)]$.
        \item Intersection: $\mu_{f_1 \cap f_2}(x)=\min [\mu_{f_1}(x),\mu_{f_2}(x)]$.
    \end{itemize}

    \newpage

    \chapter{Fuzzy logic}
    \section{Introduction}
    Logic is a tool that has been used since thousand of years to formally represent knowledge. There are meny types of logic: 
    \begin{itemize}
        \item Propositional: truth values for proposition.
        \item First order: truth values for predicates (with variables and quantifiers).
        \item Second order: predicates of predicates.
    \end{itemize}
    These types of logic are binary. We may notice that the meaning of the terms in these logics is not defined together with the formalism,
    and this is not needed to make the logic work.

    \section{Propositional logic}
    Propositional logics are concerned with propositional operators which may be applied to one or more propositions giving new propositions.
    The accent is on the truth value of propositions and on how these truth values are composed.
    \begin{remark}
        A logic is \emph{truth functional} if the truth value of a compound sentence depends only on the truth values of the consistent atomic 
        sentences, not on their meaning or structure. For such a logic the only important question about propositions is what truth values may
        have.
    \end{remark}
    In a classical, boolean or two-valued logic every proposition is either true or false and no other feature of the proposition is relevant.

    The main operators in the propositional logics are: conjunction ($\land$), disjunction ($\lor$) and negation ($\lnot$).

    \section{First order predicate logic}
    The first order logic is the same as propositional logic augmented with the possibility to define predicates on variables. Furthermore, 
    existential ($\exists$) and universal ($\forall$) quantifiers are defined. 
    In predicate logics it is possible to infer the truth value of a proposition by inferential mechanisms, such as Modus Ponens. 
    \begin{example}[Inference]
        Given the sentences: "All man are mortal" and "Socrates is a men" we can infere that "Socrates is mortal".
    \end{example}
    Inference is used to model a mechanism that we have in our minds to store a reduced amount of information and set a mechanism that can be 
    applied to derive from information other information, to face everyday situations.
    \begin{remark}
        Information and potential relationship together compose what we call \emph{knowledge}.
    \end{remark}
    
    \section{Many-valued logics}
    Aristotle already had put in evidence problems about the validity of classical logic as a knowledge representation tool. For instance, it is
    difficult to state the truth value of a proposition in the future. To solve this problem, let's introduce a third value (i.e., 0.5) for the 
    undefined situation and define a three-valued logic. From this to an infinite set of truth values there is just a small step.
    
    Infinite-value logics considers a continuumo of truth values between zero and one for example. 

    \begin{example}[Logic L1, Łukasiewicz(1930)]
        The main rules in this type of infinite-value logic are: 
        \begin{itemize}
            \item $T(\lnot a)=1-T(a)$.
            \item $T(a \land b)=\min (T(a),T(b))$.
            \item $T(a \lor b)=\max (T(a),T(b))$.
            \item $T(a \implies b)=\min (1, 1+T(b)-T(a))$.
            \item $T(a \Leftrightarrow b)=1-\left\lvert T(a)-T(b) \right\rvert$.
        \end{itemize}
    \end{example}

    This innovations bring a change in the society: things are no longer stated as true or false, probability (kolmogorov, 1929) and 
    stochasticity (Markov, 1906) became the way to represent the new approach to science and life. 

    The difference between classical logic L2 and many-valued logic L1 are the following: 
    \begin{itemize}
        \item L1 is isomorfic to the fuzzy set theory with standard operators as the classical logic L2 is isomorfic to the set theory.
        \item Tautologies are true by definition, and are used to prove theorems, so to prove the truth of an inferential chain. 
            Some tautologies valid in L2 are no longer valid in L1, for example:
            \begin{itemize}
                \item Third exluded law ($T(a \lor \lnot a)=1$)
                \item Non-contradiction law ($T(a \land \lnot a)=0$).
            \end{itemize}
    \end{itemize}

    The sentence "I'm a liar" would be a paradox in classical logic, if we give a meaning to the term "liar", since no formula can have the
    same truth value of its negation. This may not be so in many-valued logics. In Łukasiewicz logic, for instance, it can be that the truth 
    value of a sentence is 0.5, and that its negation is the same, so the proposition is consistent with the axioms, and it is not a paradox. 

    \section{Fuzzy logic}
    Fuzzy logic is an infinite-valued logic, with truth values in $[0 \dots 1]$ and prepositions are expressed as: 
    \[A \: is \: L\]
    where: 
    \begin{itemize}
        \item $A$ is a linguistic variable.
        \item $L$ is a label denoting a fuzzy set.
    \end{itemize}

    Formally, a linguistic variable is defined by a 5-tuple $(X,T(X),U,G,M)$, where: 
    \begin{itemize}
        \item $X$ is the name of the variable.
        \item $T(X)$ is the set of term for $X$, each corresponding to a fuzzy variable denoted by $T(X)$ and ranging on $U$.
        \item $U$ is the universe of discourse defined on a base variable $u$.
        \item $G$ is the syntactic rule used to generate the interpretation $X$ of each value $u$.
        \item $M$ is the semantic rule used to associate to $X$ its meaning.
    \end{itemize}
    \begin{example}[Linguistic variable for age]
        We can define a linguistic variable for the age in the following way:
        \begin{itemize}
            \item $X$ is a linguistic variable labelled "age".
            \item $U=[0 \dots 100]$.
            \item $T(X)={old, middle-aged, young, \dots}$.
            \item $u=[0 \dots +\infty]$.
            \item $M$ is the definition in terms of fuzzy sets of the values of $X$.
            \item $G$ is the fuzzy matching interpretation of $u$.
        \end{itemize}
    \end{example}

    Now that we have defined the linguistic variable it is possible to write a simple proposition in the following way: 
    \[p\: : \: X \: is \: F\]
    where:
    \begin{itemize}
        \item $X$ is a linguistic variable.
        \item $F$ is the label of a fuzzy set, defined on $U$, which represent a fuzzy predicate.
        \item $\mu_F(x)$ is the membership function defining $F$ and it is interpreted as truth value for the preposition $p$ ($T(p)=\mu_F(x)$).
    \end{itemize}
    Therefore, the truth value of the preposition $P$ is a fuzzy set defined on $[0 \dots 1]$.
    \begin{example}
        Given the simple proposition "p:temperature is high", where $X$ is temperature and $F$ is high we can find the truth value of this 
        preposition using the graph of the membership function given:
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.5\linewidth]{images/temperature.png}
        \end{figure}
        So, the truth value of the given proposition is $0.75$.
    \end{example}

    It is also possible to define qualified, non-conditional propositions with this syntax: 
    \[p \: : \: (X \: is \: F) \: is \: S\]
    where:
    \begin{itemize}
        \item $S$ is a fuzzy truth qualifier.
        \item $F$ is a fuzzy set.
        \item $p$ is truth qualified.
    \end{itemize}
    \begin{example}
        Given the conditional proposition "p:age of Tina is young is very true", where $X$ is age, $F$ is young and $S$ is very true we can 
        find the truth value of this preposition using the graph of the membership function given:
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.75\linewidth]{images/age.png}
        \end{figure}
    \end{example}

    In the fuzzy logic it is possible to use fuzzy modifiers to modify the truth values of the propositions.     
    The modifiers can be of two main types: 
    \begin{itemize}
        \item Strong ($m(a) \leq a \: \forall a \in [0 \dots 1]$): they make the predicate stronger, so they reduce the truth of the preposition.
        \item Weak($m(a) \geq a \: \forall a \in [0 \dots 1]$): they make the predicate weaker, so they increase the truth of the preposition.
    \end{itemize}
    The properties of the fuzzy modifiers are:
    \begin{itemize}
        \item $m(0)=0$ and $m(1)=1$.
        \item $m$ is a continuous function. 
        \item If $m$ is strong $m^{-1}$ is weak, and the other way around.
        \item Given another modifier $g$, the composition of $g$ and $m$ and the other way round are modifiers, too, and, if both are strong
            (or weak), so its their composition.
    \end{itemize}
    \begin{example}
        The sentence "x is young" actually means "(x is young) is true". This sentence can be modified in the following ways with fuzzy modifiers:
        \begin{itemize}
            \item "x is very young is true".
            \item "x is young is very true".
            \item "x is very young is very true". 
        \end{itemize}
        Graphically we can draw the modified membership function as: 
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.4\linewidth]{images/modifiers.png}
        \end{figure}
        where: 
        \begin{itemize}
            \item $\mu_{very \: a}(x)=\mu_a(x)^2$.
            \item $\mu_{fairly \: a}(x)=\mu_a(x)^{\frac{1}{2}}$.
        \end{itemize}
    \end{example}








     

    \newpage

    \chapter{Fuzzy rules}
    
\end{document}