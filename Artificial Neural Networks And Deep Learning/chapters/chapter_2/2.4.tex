\section{Loss function}

The loss function measures the discrepancy between the predicted outcomes of a model and the actual observed data, serving as the foundation for parameter estimation.
This concept is central to many learning algorithms and optimization problems, regardless of the underlying model or data distribution.

Let $\boldsymbol{\theta}=\begin{pmatrix} \theta_1 & \theta_2 & \dots & \theta_p \end{pmatrix}^T$ represent the vector of parameters of a model. 
The goal is to estimate the parameters $\theta$ that minimize the loss function or maximize the likelihood of observing the given data.
Here's a generalized process:
\begin{enumerate}
    \item \textit{Define the likelihood function}: The likelihood function, $\mathcal{L}(\boldsymbol{\theta})$, represents the probability of the observed data given the model parameters. 
    \item \textit{Log-likelihood transformation}: Since the likelihood function often involves a product of probabilities, it is computationally convenient to work with the log-likelihood function, $\log \mathcal{L}(\boldsymbol{\theta})$, which transforms the product into a sum. 
        This simplifies both mathematical derivations and numerical stability.
    \item \textit{Compute the gradient of the log-likelihood}: To estimate $\boldsymbol{\theta}$using Maximum Likelihood Estimation, the log-likelihood function is maximized. 
        This requires calculating the gradient and setting it to zero to identify critical points.
    \item \textit{Solve for the optimal parameters}: depending on the complexity of the model, the optimization problem can be solved:
        \begin{itemize}
            \item \textit{Analytically}: when a closed-form solution exists, such as estimating the mean of a Gaussian distribution.
            \item \textit{Numerically}: for more complex models, iterative optimization techniques like gradient descent are used to approximate the optimal parameters.
        \end{itemize}
\end{enumerate}

\paragraph*{Selection}
Choosing an appropriate loss function is crucial for defining the task and steering the learning process.
A loss function not only quantifies the difference between predicted and actual values but also plays a significant role in shaping the optimization behavior of the model.
When designing a loss function, several key factors should be considered:
\begin{itemize}
    \item \textit{Leverage knowledge of the data distribution}: it's important to integrate any prior knowledge or assumptions about the underlying data distribution when selecting a loss function. 
    \item \textit{Exploit task-specific and model knowledge}: a  good loss function should reflect the objectives of the specific task at hand.
    \item \textit{Creativity in loss function design}: predefined loss functions may not capture all aspects of the problem. 
        In such cases, creativity in designing a custom loss function can help better model the problem and improve performance.
\end{itemize}

\subsection{Perceptron}
In the case of the Perceptron, it can be shown that the error function minimized by the Hebbian rule is closely related to the distance of misclassified points from the decision boundary. 
The goal is to minimize the following loss function:
\[\mathcal{L}(\mathbf{w}) = -\sum_{i \in M} t_i (\mathbf{w}^T\mathbf{x})\]

To minimize this error function $\mathcal{L}(\mathbf{w})$ using stochastic gradient descent, we compute the gradients with respect to the model parameters. 
Stochastic gradient descent is then applied iteratively to each misclassified point:
\[\mathbf{w}_{k+1} = \mathbf{w}_k + \alpha t_i \cdot x_i \]
Here, $\alpha$ denotes the learning rate.
This iterative process adjusts the weights to progressively reduce misclassification.