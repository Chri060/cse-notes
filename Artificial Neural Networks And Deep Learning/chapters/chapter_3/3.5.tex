\section{Other problems}

\subsection{Semantic segmentation}
Semantic segmentation is a computer vision task that involves grouping pixels in an image that share common characteristics or belong to the same object category. 
The main objective of semantic segmentation is to assign a label from a predefined set of categories $\Lambda$ to each pixel $(r, c)$ in an image $\mathbf{I}$.
Unlike instance segmentation, which distinguishes between different instances of the same object category, semantic segmentation only focuses on classifying pixels based on their category. 
In other words, all pixels belonging to the same category share the same label, without differentiating between individual objects of that category.

Formally, semantic segmentation can be described as a mapping function:
\[\mathbf{I}\rightarrow \mathbf{S}\in\Lambda^{R\times C}\]
Here, $\mathbf{S}$ represents the segmentation map, where each element $S(x, y)$ is a class label assigned to the pixel at position $(x, y)$. 
The output $\mathbf{S}$ is a grid of size $R \times C$ (the resolution of the image), with each pixel labeled according to its corresponding class in the set $\Lambda$.

\subsubsection{Fully Convolutional Neural Networks}
Fully Convolutional Neural Networks are an extension of traditional Convolutional Neural Networks, designed to overcome the constraint of fixed input sizes. 
Unlike conventional Convolutional Neural Networkss, which rely on Fully Connected layers that require a fixed-size input, Fully Connected Convolutional Neural Networks eliminate these layers and replace them with convolutional and subsampling layers that operate across the entire image.

In Fully Convolutional Neural Networks, the convolutional and pooling layers slide over the entire input image, regardless of its size, producing feature maps whose resolution scales appropriately with the input dimensions.
Crucially, the spatial extent of the latent space is preserved throughout the network, meaning the spatial relationships between features are maintained across all layers. 

For each output class, Fully Convolutional Networks generate a heatmap, where the resolution of the heatmap is typically lower than the input image, amd each position in the heatmap represents the class probabilities for the corresponding region in the input image, based on the receptive field of the convolutional layers.

\paragraph*{Classification to segmentation}
The process of transforming a pre-trained Fully Convolutional Neural Network designed for classification into a semantic segmentation network involves adapting the model to handle input images of arbitrary size while maintaining high-resolution, pixel-level predictions.
A common challenge in this transformation is that the heatmaps produced by the classification network are typically low-resolution, which makes it difficult to achieve accurate pixel-wise segmentation. 
The goal is to improve the precision of the segmentation by refining the coarse predictions generated by these heatmaps.
Several approaches can be used to overcome this challenge:
\begin{itemize}
    \item \textit{Direct heatmap prediction}: this method generates heatmaps directly from the network, but it often results in imprecise predictions due to the use of masks that cover regions larger than a single pixel.
    \item \textit{Shift and stitch}: leverages the downsampling factor, which is the ratio of the input size to the output heatmap size. 
        It involves computing heatmaps for all possible shifts of the input image. These shifted heatmaps are then stitched back together, with each heatmap's pixel corresponding to the center of the receptive field. 
        While this method improves prediction accuracy, it is computationally expensive due to the need to process multiple shifts of the image.
    \item \textit{Learned upsampling}: eliminates strides in pooling layers, whether max-pooling or convolutional. 
        By doing so, it supports end-to-end learning and allows the network to perform inference directly on full-sized images.
        This method enables fine-tuning of pre-trained classification models for segmentation tasks, and it can be trained to learn how to effectively upsample the low-resolution heatmaps into high-resolution pixel predictions.
\end{itemize}

\subsubsection{U-net}
A common approach to semantic segmentation involves cropping the input image into patches, classifying each patch individually, and assigning the predicted class label to the central pixel of the patch. 
While this method is straightforward, it has notable limitations, such as a small receptive field and low efficiency, as it does not capture long-range dependencies and global context well.

Semantic segmentation inherently involves a trade-off between semantic understanding and spatial localization. 
On one hand, fine-grained details are crucial for accurate pixel-level predictions, while on the other hand, a global understanding of the image structure is necessary to provide coherent segmentation. 
To address this, segmentation models typically combine fine-grained layers (which capture local details) with coarse layers (which provide broader contextual information). 
This fusion enables the model to make localized predictions that respect the global structure of the image, improving both accuracy and spatial coherence.

A typical semantic segmentation network consists of two main components:
\begin{enumerate}
    \item \textit{Encoder}: the encoder functions similarly to a standard classification network. 
        It uses a Convolutional Neural Network to progressively extract high-level features from the input image, reducing the spatial resolution while capturing essential semantic information.
    \item \textit{Decoder}: the decoder is responsible for reconstructing the spatial resolution by upsampling the encoded features. 
        This step converts the high-level features back into pixel-level predictions, preserving fine details and sharp contours. 
        Effective upsampling is crucial for accurate localization and precise class predictions. 
        Several methods are used to reconstruct spatial resolution during the decoding process: 
        \begin{itemize} 
            \item \textit{Nearest neighbor interpolation}: this method simply duplicates values to increase resolution. 
            \item \textit{Bed of nails}: values are placed at specific positions within an expanded matrix, with the remaining entries set to zero. 
        \item \textit{Transpose convolution}: this technique learns filters for upsampling, which can be implemented as a combination of standard upsampling followed by a convolutional layer. 
        \end{itemize} 
\end{enumerate}
While deep networks are necessary for extracting high-level semantic features, excessive downsampling can result in the loss of fine-grained spatial resolution. 
To mitigate this, many semantic segmentation networks incorporate: 
\begin{itemize} 
    \item \textit{Skip connections}: these direct connections pass features from the encoder to the decoder, ensuring that fine-grained details are preserved during the reconstruction process. 
    \item \textit{Layer fusion}: by combining features from both shallow and deep layers, the model can retain spatial precision while benefiting from rich semantic context. 
\end{itemize}

\paragraph*{Loss function}
In semantic segmentation, the categorical cross-entropy loss is commonly used to evaluate model performance at the pixel level. 
This loss function is computed pixel-wise, with the overall loss being the sum of the individual pixel losses across the entire image or a specified region of interest. 
Each pixel's contribution ensures that the model optimizes performance across the entire image.

When processing an image or a region within it, the pixel-wise losses provide a mini-batch estimate for gradient computation, which allows for efficient training, even with large images. 
This approach enables the model to optimize its parameters effectively while ensuring precise segmentation at the pixel level.

The U-Net is a specialized neural network architecture developed for semantic segmentation, particularly suited for biomedical image analysis. 
Its distinctive U-shaped structure is the basis for its name and is composed of the following components:
\begin{itemize} 
    \item \textit{Contracting path}: this part of the network consists of a series of repeated blocks.
        Each block typically includes two $3 \times 3$ convolutions followed by ReLU activation and a max pooling operation. 
        This downsampling process progressively captures high-level features while reducing the spatial dimensions of the image. 
    \item \textit{Expanding path}: this path mirrors the contracting path, consisting of blocks that progressively upsample the feature maps. 
        Each block includes an upsampling operation followed by two $3 \times 3$ convolutions with ReLU activation.
        The expanding path helps recover spatial resolution, converting the encoded features back into pixel-level predictions. 
    \item \textit{Final layer}: the final layer uses a $1 \times 1$ convolution to reduce the feature maps to the desired number of output classes, $N$, allowing the network to classify each pixel into one of the predefined categories. 
\end{itemize}
The key strength of U-Net lies in its ability to maintain spatial information throughout the process. 
The architecture is fully convolutional, which means that it can handle input images of varying sizes. 
Unlike traditional Fully Connected layers, the convolutional approach ensures that spatial dependencies are preserved.

Additionally, U-Net employs full-image training and typically uses a weighted loss function to address the challenge of imbalanced datasets, which is common in tasks like biomedical image segmentation. 
The weighted loss function ensures that the network performs well even on underrepresented classes, and it helps improve the classification of small or boundary regions in images.

\subsubsection{Training}
The training process for semantic segmentation can be approached in two primary ways:
\begin{itemize}
    \item \textit{Patch-based training}: in this approach, a classification network is trained using patches cropped from annotated images. 
        Each patch is assigned the label corresponding to the pixel at its center. During training, the network minimizes the classification loss over a mini-batch of patches. 
        Batches are randomly assembled, and resampling is often used to address class imbalance, ensuring that underrepresented classes are included more frequently in the training data. 
        However, patch-based training can be computationally inefficient, as convolution operations are redundantly applied to overlapping regions of the input image, leading to wasted resources and slower training times.
        \item \textit{Full-image training}: in this method, the entire image region effectively serves as a mini-batch, allowing the network to compute gradients more efficiently. 
            For Fully Convolutional Networks, full-image training is conceptually similar to patch-wise training, but the batch consists of all receptive fields from the network's units within the image. 
            This eliminates the redundant convolution computations associated with overlapping patches, making full-image training significantly more efficient. 
            Furthermore, it supports end-to-end learning, as the network processes the whole image in one go, improving both performance and computational efficiency.

\end{itemize}
While patch-based training offers flexibility, particularly in addressing class imbalance through patch resampling, it suffers from inefficiencies due to redundant convolution calculations for overlapping regions.
Full-image training, on the other hand, takes advantage of the spatially efficient operations of Fully Convolutional Networks, avoiding redundant computations. 
However, full-image training introduces its own challenges. 
Full-image training, which processes entire image regions, tends to reduce this randomness. 
To reintroduce stochasticity, techniques like random masking of image regions can be applied.

Additionally, full-image training does not have the flexibility to resample patches for balancing class frequencies. 
To address class imbalance, it is common to weight the loss function to account for differences in label frequency across the image. 
This ensures that the network gives more emphasis to underrepresented classes, leading to more balanced performance across all segments of the image.

\subsection{Localization}
Localization involves identifying the position of an object within an image and classifying it. 
The task is to assign the object class to the image from a fixed set of categories, and then locate the object within the image by predicting the bounding box around it.
To train a model for localization, an annotated training set is required, where each image has a label and a bounding box around the object.

Formally, we want to map an input image $\mathbf{I}\in \mathbb{R}^{R\times C \times 3}$ to the bounding box coordinates $(x,y, h, w)$: 
\[\mathbf{I}\rightarrow(x,y, h, w)\]
Here, $(x, y)$ are the coordinates of the top-left corner of the bounding box, and $(h, w)$ are the height and width of the bounding box, respectively.

One straightforward solution is to train a regression network to directly predict the bounding box coordinates.
This approach involves training a network to predict the class label and the coordinates simultaneously in a multi-task learning setting.
This means that the network must predict both categorical and continuous outputs.
Thus, the network must handle both a classification task and a regression task simultaneously, making it a multi-task learning problem. 
Since the two outputs (class label and bounding box) have different natures (discrete for class and continuous for bounding box), the training process needs to combine these two tasks.

\paragraph*{Loss function}
To optimize both the classification and regression tasks, we use a combined loss function. 
The multi-task loss function is a weighted sum of two separate losses:
\[\mathcal{L}(\mathbf{x})=\alpha\mathcal{S}(\mathbf{x})+(1-\alpha)\mathcal{R}(\mathbf{x})\]
Here, $\mathcal{S}(\mathbf{x})$ is the classification loss, $\mathcal{R}(\mathbf{x})$ is the regression loss, and $\alpha\in[0,1]$ is a hyperparameter that controls the trade-off between classification and regression losses.

Choosing an optimal value for $\alpha$ can be challenging, and cross-validation is recommended to tune this parameter effectively.
It's important to note that simply adjusting $\alpha$ might not yield meaningful results; a better approach is to monitor the performance of the combined loss function and adjust based on empirical results.

To implement the multi-task loss function, the training loop must be adjusted to compute both losses for each image, combine them, and backpropagate the total loss. 
This allows the model to optimize for both tasks simultaneously, adjusting the parameters based on the combined objective.

\subsubsection{Weakly Supervised Learning}
In Supervised Learning, a model $\mathcal{M}$ performs inference from input data $X$ to output labels $Y$, as shown by the following mapping: 
\[\mathcal{M}:X\rightarrow Y\]
This requires a training set, where the training pairs consist of labeled data that are of the same type as the classifier's input and output. 
However, for certain tasks, such as segmentation, gathering such annotated data can be expensive and time-consuming.

Weakly Supervised Learning aims to overcome the challenge of expensive annotations by utilizing labels that are easier to gather.
The model is trained on a different domain $K$ and is expected to perform inference in the target domain $Y$. 
In other words, weak supervision allows the model to solve a task using labels that are not as detailed or expensive to collect as the ideal annotations.

\paragraph*{Class Activation Mapping}
Class Activation Mapping is a technique used to visualize which regions of an image a model focuses on when making classification decisions. 
It works by highlighting the areas of the image that contribute the most to the prediction of a specific class.

To apply Class Activation Mapping, a Convolutional Neural Network must meet the following criteria: a Global Average Pooling layer and a single Fully Connected layer follows the Global Average Pooling layer. 

To btain the saliency maps the following steps are needed: 
\begin{enumerate}
    \item \textit{Feature maps and Global Average Pooling}: after the convolutional block of the Convolutional Neural Network, there are $n$ feature maps $f_k(x,y)$, each having a resolution close to that of the input image.
        The Global Average Pooling layer computes the average of each feature map, resulting in $n$ scalar values. 
    \item \textit{Fully Connected layer and class scores}: the Fully Connected layer computes the class scores for a specific class $S_c$ as a weighted sum of the Global Average Pooling outputs:
        \[S_c\sum_{k}w_k^cF_k\]
        Here, $w^c_k$ represents the importance of feature map $k$ for class $c$.
    \item \textit{Reinterpreting class scores}: the class scores $S_c$ can be rewritten as:
        \[S_c=\sum_{x,y}\sum_kw_k^cf_k(x,y)\]
    \item \textit{Defining the Class Activation Mapping}: 
        \[M_c(x,y)=\sum_kw_k^cf_k(x,y)\]
        Here, $M_c(x,y)$ indicates the importance of the activations at position $(x,y)$ for predicting class $c$. 
\end{enumerate}
Global Average Pooling layer encourages the identification of the entire object because all activation values contribute to the classification.
Global Max Pooling focuses on specific discriminative features, as only the highest activation value influences the classification. 
This makes Global Max Pooling more suitable for tasks that rely on identifying distinctive features rather than the entire object.

\paragraph*{Weakly Supervised localization}
In the context of localization, the goal is to predict the coordinates of a bounding box around an object in an image. 
However, obtaining annotated bounding boxes for every image can be expensive.
Instead, we can train a model to perform localization using a dataset annotated only with image-class labels, without bounding box information.
By training a classifier using image-class labels, the model can still learn to estimate the location of the object in the image. 
The model essentially learns to perform localization by leveraging the class information and applying weak supervision to make localization predictions, even when the full set of annotations is unavailable.
For Weakly Supervised localization we can use thresholding Class Activation Mapping values. 

\subsubsection{Convolutional Neural Networks visualization}
Visualization techniques provide insight into the internal functioning of Convolutional Neural Networks by highlighting the features and regions that contribute to a network's decision. 
These techniques can be particularly useful for understanding, debugging, and trusting the model's predictions.

The filters in the first convolutional layer are relatively straightforward to interpret. 
Deeper layers represent higher-level abstractions, combining lower-level features into complex patterns and objects.

\paragraph*{Neuron activation}
To understand what a specific neuron in a deep layer responds to:
\begin{enumerate}
    \item Select a neuron from a deep layer of a pretrained Convolutional Neural Network.
    \item Perform inference on multiple input images and record the activations of the selected neuron.
    \item Identify the image that maximally activates the neuron.
    \item Extract the receptive field (the image patch influencing the activation).
    \item Repeat the process for multiple neurons to understand the broader feature representations.
\end{enumerate}

\paragraph*{Generate images}
Another approach is to generate synthetic images that maximize the activation of a specific neuron or class score:
\begin{enumerate}
    \item Define an objective to maximize the class score $S_c(\mathbf{I})$ for a given class $c$, regularized for smoothness:
        \[\hat{\mathbf{I}}=\argmax_\mathbf{I} S_c(\mathbf{I})+\lambda{\left\lVert \mathbf{I}\right\rVert}_2^2 \]
    \item Optimize $\hat{\mathbf{I}}$ via gradient ascent over the input $\mathbf{I}$. 
    \item Repeat for neurons or classes to visualize different aspects of the network's learned representations.
\end{enumerate}

\paragraph*{Explanation}
Visualization techniques like saliency maps, Grad-Class Activation Mapping, and Class Activation Mapping highlight the regions of the image influencing the network's predictions. 
Saliency maps can help uncover systematic errors in the network, such as: misfocusing on irrelevant regions and failing to capture key features.
Visualization fosters interpretability, especially for critical applications.
Understanding model behavior builds confidence in its predictions and reveals potential biases.

\subsection{Human pose estimation}
Human pose estimation is a task that involves predicting the locations of body joints in an image, which can be framed as a Convolutional Neural Network regression problem.
This task is fundamentally a localization problem, where the goal is to detect key points corresponding to the human body.

The network receives the entire input image, allowing it to capture the full context of each body joint. 
This holistic approach helps the network learn spatial relationships between joints more effectively. 
The design and training of the network are relatively straightforward, with transfer learning from pre-trained classification networks offering a significant advantage in addressing common training challenges.

Pose is represented as a vector containing the coordinates of $k$ joints, where each joint is described by its two-dimensional coordinates. 
In some cases, the pose vector may be normalized with respect to the bounding box that encloses the human body to maintain scale invariance.

The network is trained to predict a vector of size $2k$, where each pair of consecutive values represents the coordinates of each joint.
This approach allows for the representation of human pose in terms of joint positions.

One challenge in pose estimation is that not all joints may be visible in the input image, due to occlusion or out-of-frame parts of the body. 
In such cases, the network is designed to always produce a fixed or default value for the invisible joints, allowing it to handle occlusions gracefully.

To prevent overfitting and improve generalization, augmentation techniques such as translation and flipping are applied to the training data. 
These augmentations help the network become more robust to variations in the position and orientation of the human body within the image.

\subsection{Object detection}
Given a predefined set of categories $\Lambda$ and an input image $\mathbf{I}$, the taks involves detecting and drawing bounding boxes around each object instance adn asssign a category label $l$ to each bounding box.

Assigning multiple labels to an input image $\mathbf{I} \in \mathbb{R}^{R \times C \times 5}$ involves associating each instance of an object with a bounding box and a corresponding category label.
The goal is to identify the coordinates $\{(x,y, h, w)_i\}$ of the bounding box enclosing each object instance, along with its label $l_i\in\Lambda$, where $\Lambda$ is a predefined set of categories. 
This can be expressed as:
\[\mathbf{I}\rightarrow \{(x,y,h,w,l)_1,\dots, (x,y,h,w,l)_n\}\]
Here, $n$ is the number of object instances in the image.
A training set annotated with labels and bounding boxes for each object.

\subsubsection{Sliding window}
This approach is similar to the sliding window method used in semantic segmentation but adapted for object detection.: 
\begin{enumerate}
    \item \textit{Pretrained model}: use a model trained to process a fixed input size.
    \item \textit{Sliding window}: slide a window of the model's input size across the image and classify each region within the window.
    \item \textit{Background class}: ensure the model includes a background class to differentiate between objects and non-object areas.
\end{enumerate}
The problems with this technique is that it is inefficient and it is difficult to detect scale variability. 

\subsubsection{Region proposal}
Region proposal algorithms (and networks) aim to identify bounding boxes that correspond to candidate objects in an image. 
These algorithms prioritize high recall (detecting most objects) over precision (reducing false positives).
With Deep Learning, region proposal methods have become more sophisticated and integrated into modern object detection pipelines.

The approach involves: 
\begin{enumerate}
    \item Generate candidate bounding boxes that likely contain objects.
    \item Use a Convolutional Neural Network to classify the image content within each proposed region.
\end{enumerate}
Region proposals are refined using regression to improve bounding box accuracy.
A pretrained Convolutional Neural Netwokr is fine-tuned for the specific object classes. 
A Fully Connected layer is added after feature extraction for classification.

We need to include a background class to filter out regions that do not correspond to objects.

\paragraph*{Loss function}
Quantifying the network's performance requires assessing how well the detections match the ground truth annotations. 
A key metric is the Intersection over Union:
\[\text{IoU}=\dfrac{\text{area of overlap}}{\text{area of union}}\]
The loss function evaluates the predictions $\hat{y}$ against the annotations $y$. 
This loss includes the undetected objects, the missclassified objects and the correct dimension of the boxes. 

\paragraph*{Limitations}
The main limitations of region proposal methods include their reliance on separate, unoptimized algorithms for generating proposals, which are not jointly trained with the detection pipeline.
Training is slow and resource-intensive, requiring significant storage for features and long processing times. 
Inference is also inefficient, as the Convolutional Neural Network must process each proposal independently, leading to redundant computations. 
Additionally, the training process involves ad-hoc objectives preventing true end-to-end optimization. 
These inefficiencies can hinder both accuracy and speed, making them less practical for real-time applications.

\subsubsection{Fast Region Based Convolutional Neural Network}
Fast Region Based Convolutional Neural Network improves upon traditional Region Based Convolutional Neural Network by introducing significant optimizations in both training and inference, enabling faster and more efficient object detection.
The steps are as follows: 
\begin{enumerate}
    \item \textit{Feature map extraction}: the entire image is passed through a Convolutional Neural Network to extract feature maps.
    \item \textit{Region proposal projection}: region proposals are identified directly from the image and mapped onto the extracted feature maps. 
        This allows regions to be cropped from the feature maps instead of the original image.
    \item \textit{Fixed-size region of interestpooling}: since Fully Connected layers require fixed-size inputs, each Region of Interest is divided into smaller grid, and region of interestpooling applies max-pooling over the grid to produce a fixed-size activation. 
        This output is vectorized and passed to subsequent layers.
    \item \textit{Multitask learning}: Fully Connected layers predict both object classes and bounding box locations.
        A multitask loss function, combining classification and regression losses, is optimized during training.
    \item \textit{End-to-end training}: the entire network is trained in an end-to-end manner, with gradients back-propagated through the Convolutional Neural Network, region of interestpooling, and Fully Connected layers.
        The convolutional computations are executed only once per image, regardless of the number of regions.
\end{enumerate}
Fast Region Based Convolutional Neural Network significantly improves inference speed compared to Region Based Convolutional Neural Network, as convolutional operations are no longer repeated for overlapping regions.
Most of the computational time is now spent on region proposal extraction. 

\subsubsection{Region Proposal Network}
The Region Proposal Neural Network replaces traditional region of interestextraction algorithms with a trainable network that operates on the same feature maps used for classification, improving efficiency and integration. 
Region Proposal Neural Network is implemented as a small convolutional neural network that outputs potential bounding box proposals and objectness scores for each region.

At each spatial location in the feature map, Region Proposal Neural Network generates $k$ anchor boxes with predefined scales and aspect ratios.
A convolutional layer reduces the feature map to a lower-dimensional vector.
Anchor classification predicts the probability that each anchor contains an object (objectness score).
Bounding box regression refines anchor box coordinates to better match ground truth bounding boxes.
The final outputs are $2k$ objectness scores and $4k$ bounding box corrections.

The Region Proposal Neural Network proposals are passed to the detection head, which performs:
\begin{itemize}
    \item \textit{Region of interest}: crops and resizes features from the latent space for each proposal into a fixed-size representation.
    \item \textit{Classification}: Fully Connected layers predict object classes, including a background class.
    \item \textit{Bounding box refinement}: further adjusts bounding box locations.
\end{itemize}
The detection head produces $L$ classification scores (one per class, including background) and $4L-4$ bounding box corrections.

Training involves optimizing a multi-task loss that combines: objectness loss, regression loss, final classification loss, and final bounding box regression loss,

\paragraph*{Advantages}
Fully trainable in an end-to-end manner, with Region Proposal Neural Network integrated directly into the pipeline.
Faster inference compared to Fast Fast Region Based Convolutional Neural Network, as redundant computations are eliminated.
High accuracy and efficiency by leveraging a shared feature map for both region proposal and detection.

\subsubsection{You Only Look Once}
The Neural Network works as follows: 
\begin{enumerate}
    \item \textit{Image division into a grid}: the image is divided into a coarse grid. 
    \item \textit{Anchor boxes for each cell}: each grid cell contains $B$ anchor boxes (base bounding boxes). 
        For each anchor, the network predicts: he adjustments to the base bounding box to better match the object: and the classification scores for the object within the bounding box, across $C$ categories (including the background).
    \item \textit{Single forward pass}: the entire prediction is completed in a single forward pass through the image using a single Convolutional Neural Network.
\end{enumerate}
Training You Only Look Onceinvolves challenges, particularly in defining the loss function to balance matched and unmatched predictions effectively.

You Only Look Onceshare similarities with the Region Proposal Neural Network used in Faster Region Based Convolutional Neural Network.
Region Proposal Neural Network are typically more accurate.
Single-shot detectors are faster but trade off some accuracy for speed.

\subsection{Instance segmentation}
Instance segmentation involves assigning multiple labels and associated information to an input image $\mathbf{I}$. 
Each object in the image is identified by a unique label $l_i$, drawn from a fixed set of categories $\Lambda$. 
For each object, the network predicts the coordinates of the bounding box that encloses it, given by $(x_i, y_i, h_i, w_i)$, where $x$ and $y$ are the center position of the box, and $h$ and $w$ are its height and width.

Additionally, for each object, the network identifies the set of pixels $S_i$ that lie within the bounding box, corresponding to the pixels that belong to that object instance. 
The final output is a set of predictions for all detected objects, expressed as:
\[\mathbf{I} \rightarrow \{(x_i, y_i, h_i, w_i, l_i, S_i)\}_{i=1}^N\]
Here, $N$ is the number of objects detected.

This task combines the challenges of object detection, which involves handling multiple object instances in an image, and semantic segmentation, where each pixel is assigned a label. 
The complexity of instance segmentation arises from the need to not only detect multiple objects but also to precisely segment each instance of the object and assign the correct label to each pixel in the scene.

\subsubsection{Mask-RConvolutional Neural Network} 
Similar to Faster Region Based Convolutional Neural Network, Mask Region Based Convolutional Neural Network performs object detection by classifying each region of interest and estimating the corresponding bounding boxes. 
However, it extends Faster Region Based Convolutional Neural Network by adding an additional branch for predicting object masks in parallel with the existing branch for bounding box recognition. 

In Mask Region Based Convolutional Neural Network, semantic segmentation is performed within each region of interest, where the mask for each object instance is predicted separately for each class. 
The network estimates a binary mask for each region of interestcorresponding to each class label, capturing the precise object boundaries. 
This addition makes Mask Region Based Convolutional Neural Network capable of performing both object detection (via bounding boxes) and instance segmentation (via pixel-level object masks).

Mask Region Based Convolutional Neural Network builds upon the Faster Region Based Convolutional Neural Network backbone, which is responsible for extracting features, and incorporates the mask prediction branch. 
The loss function for training includes both the bounding box loss and the mask estimation loss, ensuring that the network learns to both detect objects and generate accurate masks.

\subsubsection{Feature Pyramid Network}
The goal of a Feature Pyramid Network is to leverage the inherent pyramidal structure of a Convolutional Neural Network feature hierarchy while creating a feature pyramid that retains strong semantic meaning at all scales. 
Feature Pyramid Network combines semantically strong features (low resolution) with semantically weak features (high resolution) through a top-down pathway and lateral connections.

Feature Pyramid Network addresses the need to recognize objects at vastly different scales. 
Traditional approaches used image pyramids, where the image is resized at multiple scales to capture features at various resolutions. 
However, using these image pyramids during inference and training led to significant increases in memory usage and inference time. 
Additionally, training in an end-to-end manner with image pyramids was infeasible. As a result, many methods only used image pyramids during inference, leading to inconsistencies between training and inference stages.

\paragraph*{Components}
Feature Pyramid Network produces predictions independently at each level of the feature pyramid. 
Instead of using multi-scale image pyramids, Feature Pyramid Network builds its feature pyramid directly from the input image and generates proportionally sized feature maps at different scales.
The input is a single-scale image of arbitrary size.
The output is a proportionally sized feature maps at multiple levels of the pyramid.
The main components are: 
\begin{enumerate}
    \item \textit{Bottom-up pathway}: this pathway creates feature maps at progressively smaller spatial dimensions as it moves upward through the network. 
        The output of each convolutional layer in the bottom-up pathway is used as input to the top-down pathway.
    \item \textit{Top-down pathway}: the top-down pathway derives higher resolution features by upsampling the feature maps produced by the bottom-up pathway. 
        These features are enhanced with information from the bottom-up pathway via lateral connections. 
    \item \textit{Lateral connections}: these connections combine features from different layers in the bottom-up pathway with features from the top-down pathway. 
        The lateral connections reduce the channel dimension and help refine the features as they are passed upward through the network.
\end{enumerate}
Feature Pyramid Network is not an object detector by itself but serves as a feature extractor that can be combined with an object detector. 
Since the predictor head slides over all locations in all pyramid levels, it eliminates the need for multi-scale anchors at specific levels. 
This allows Feature Pyramid Network to efficiently recognize objects at different scales while maintaining consistency in training and inference.

\subsection{Metric learning}
In a face identification system, a simple approach using a Convolutional Neural Network for classification can be a good starting point.
However, this setup has limitations when it comes to handling new individuals. 
In traditional Convolutional Neural Network classification, once a network is trained, it would need to be retrained entirely if a new person is added. This approach becomes inefficient as the number of individuals grows.

A more practical solution involves a metric learning approach, where we store a picture (or a template) for each individual, and then identify an individual by comparing the input image to the stored templates. 
The identification process becomes:
\[\hat{i}=\argmin_{j=1,\dots,3}={\left\lVert \mathbf{T}-\mathbf{T}_j\right\rVert}_2 \]
Here $\mathbf{T}$ represents the input image and $\mathbf{T}_j$ are the templates stored in the database.
This method makes enrollment straightforward, as adding a new person simply involves adding their template to the database. 
However, the challenge lies in how to perform the identification efficiently by learning a better distance measure for comparing images.

In a typical Convolutional Neural Networks setup, the feature extraction part is generally more versatile than the classification part. 
The feature extractor learns a latent representation of the input image which captures useful patterns that help in classification.
This latent representation can also be used for image retrieval, where we compare images based on their latent representations.
However, the original network was not specifically trained for comparison. 

\paragraph*{Metric learning}
In metric learning, the goal is to train the Convolutional Neural Network to measure the distance between images in a way that preserves semantic meaning. 
Specifically, we want the network to learn the distance such that:
\[{\left\lVert f_{\mathbf{w}}(\mathbf{I})-f_{\mathbf{w}}(\mathbf{T}_i)\right\rVert}_2<{\left\lVert f_{\mathbf{w}}(\mathbf{I})-f_{\mathbf{w}}(\mathbf{T}_j)\right\rVert}_2\]
Here, $f_w(\mathbf{I})$ is the feature extracted from the input image $\mathbf{I}$ and $f_{\mathbf{w}}(\mathbf{T}_i)$ is the feature extracted from the template $\mathbf{T}_i$, for the same individual $i$. 
The network should learn to minimize the distance between the input image and the correct template, while maximizing the distance to incorrect templates.

his approach uses Siamese Networks, where two identical networks (sharing the same weights $\mathbf{w}$) process two images simultaneously. 
The goal is to learn the weights such that the network can compare image pairs and measure their similarity.

During training, the Siamese network is fed with pairs of images, which may or may not refer to the same person. A contrastive loss function is typically used to train the network:
\[\mathbf{w}=\argmin_\omega\sum_{i,j}\mathcal{L}(\mathbf{I}_i,\mathbf{I}_j,y_{i,j})\]

\paragraph*{Triplet loss}
Another commonly used loss function in metric learning is triplet loss. 
This loss function compares three images: a positive image $\mathbf{P}$, a negative image $\mathbf{N}$, and a query image $\mathbf{I}$. 
The triplet loss function is designed to minimize the distance between $\mathbf{I}$ and $\mathbf{P}$ (both images of the same person) while maximizing the distance between $\mathbf{I}$ and $\mathbf{N}$ (images of different people):
\[\mathcal{L}_q(\mathbf{I}, \mathbf{P}, \mathbf{N}) = \max \left( 0, m + {\left\lVert f_\mathbf{w}(\mathbf{I}) - f_\mathbf{w}(\mathbf{P}) \right\rVert}_2^2 - {\left\lVert f_\mathbf{w}(\mathbf{I}) - f_\mathbf{w}(\mathbf{N}) \right\rVert}_2^2 \right)\]
Here, $m$ is a margin that enforces a minimum separation between positive and negative pairs. 
The triplet loss ensures that the network learns to distinguish between individuals by embedding similar individuals closer together in the feature space while keeping different individuals farther apart.
The selection of triplets during training is crucial, and many methods have been developed to intelligently sample triplets that will improve the training efficiency.