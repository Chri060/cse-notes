\section{Layout}

The Vulkan graphics pipeline processes rendering as follows:
\begin{itemize}
    \item \textit{Mesh initialization}: it begins with a mesh defined by a set of vertices and indices.
    \item \textit{Vertex processing}: each vertex is processed by a vertex shader, which computes its normalized screen coordinates and other parameters to pass to the fragment shader.
    \item \textit{Fragment processing}: for every fragment (pixel) on the screen, the fragment shader computes the final color of the pixel, implementing algorithms like the Bidirectional Reflectance Distribution Function (BRDF).
\end{itemize}

\paragraph*{Pipelines}
The graphics pipeline in Vulkan, while based on a set of fixed functions configurable by the user, must support a wide array of use cases, each with unique characteristics. 
Because there is no one-size-fits-all solution, Vulkan provides users with extensive programming capabilities to tailor the pipeline to their specific needs.
Besides allowing custom shader writing, Vulkan enables users to:
\begin{itemize}
    \item \textit{Vertex data definition}: specify which information is associated with vertices.
    \item \textit{Shader communication}: define the information passed between vertex and fragment shaders and determine if and how it is interpolated.
    \item \textit{Shader parameters}: define additional parameters that can be passed to shaders for proper vertex processing and fragment computation.
\end{itemize}

\subsection{Data structure}
In Vulkan, the term Layout encompasses any data structure employed to specify the format and type of information within user-defined encodings. 
This includes defining pixel color encodings such as the number of bits per pixel, selected color space, and the presence of an alpha-channel.

However, the term "Layout" is sometimes ambiguously used in Vulkan documentation, leading to confusion regarding its context. 
This ambiguity can be problematic when referencing related documentation and tutorials.

Despite this ambiguity, Vulkan manages layouts in a manner that encourages reusability whenever possible. 
Moreover, Vulkan emphasizes interoperability among shaders, vertices, and various data blocks, facilitating the mixing and matching of data types that yield identical results.

\paragraph*{Vertex attributes}
In GLSL, in and out global variables serve as the interface between shaders and other components of the pipeline, whether fixed or programmable.
Within the graphics pipeline, vertex-related values are directly transmitted to the Vertex Shader by the Input Assembler component. 
Specifically, vertex coordinates are conveyed through in variables of the Vertex Shader.

Each vertex possesses an implicit integer index represented by the global variable \\\texttt{gl\_VertexIndex}. 
Additionally, vertices can feature an arbitrary array of user-defined attributes, each characterized by one of the supported GLSL types. 
Some vertices may lack user-defined attributes altogether.

For instance, in a 2D game application, a set of vec2 normalized screen coordinates might directly denote element positions. 
Conversely, a typical 3D scene employs at least a vec3 element to store positions in 3D local space. 
Other pipelines might necessitate vec3 position attributes (measured in 3D local coordinates) and vec3 color attributes to vary diffuse reflection across object surfaces.

Consistency is crucial: all vertices within a mesh must adhere to the same vertex format, i.e., share the same attributes. 
The pipeline's fixed functions facilitate the transmission of such values to the Vertex Shaders.

Different meshes may feature distinct vertex formats, albeit requiring the creation of separate pipelines. 
Vulkan offers exceptional flexibility in configuring pipelines to specify the vertex attributes transmitted to the Vertex Shader.
Specifically, Vulkan enables the partitioning of vertex data into separate arrays, each containing specific attributes. 
These arrays, known as bindings, are distinguished by progressive binding IDs. 
Although various approaches exist, employing a single binding is most common.

Typically, a C++ structure encapsulating all vertex attributes is created, utilizing GLM types aligned with those defined in the corresponding Vertex Shader. 
This binding is defined within a VkVertexInputBindingDescription structure, featuring fields specifying the binding ID and object size in bytes.
The inputRate field accommodates instanced rendering, a concept elaborated on in subsequent lessons.

Individual attributes are defined within elements of an array of \\\texttt{VkVertexInputAttributeDescription} structures. 
Each attribute definition includes specifications for both its binding and location IDs, along with a constant denoting its data type (format). 
Lastly, the byte offset within the data structure for the respective field must be provided, computable using the C++ \texttt{offsetof()} macro.

To synchronize global variables with corresponding vertex attributes, the Vertex Shader employs the \texttt{layout(location)} directive.

\subsection{Vertex and fragments shaders}
In Vulkan, only the vertex shader has access to attributes. These values must be passed to other pipeline components using out variables. 
Vertex attributes, communicated through in and out variables, are organized into slots, each identified by a location number starting from zero. 
These location numbers are constrained by a hardware-dependent constant, typically sufficient for standard applications. 
When defining in or out variables, the user specifies the slot's location ID in a layout directive. 
Notably, only slot numbers are utilized, allowing the corresponding global variable names to vary between shaders.

The Input Assembler configures the slots utilized by the Vertex Shader's in variables, which are available for communication. 
Additionally, pipeline configuration dictates the out variables written by the Fragment Shader. 
Typically, this includes the final pixel color, but advanced applications may compute additional values. 
Communication between the Vertex and Fragment shaders adheres to their GLSL specifications. 
The pipeline's fixed functions interpolate out variable values from the Vertex Shader based on pixel positions on the screen before passing them to the Fragment Shader.

By default, interpolation between Vertex and Fragment shaders employs Perspective Correct techniques.
However, this behavior can be modified using directives like flat and noperspective preceding in and out variables.

\subsection{Uniform buffers}
When we introduced GLSL, we discussed how applications can send scene- and mesh-dependent data to shaders using Uniform Blocks as global variables. 
This approach is also used for passing textures to shaders. Uniform blocks are accessed using a two-level indexing system.

Some shader parameters are dependent on the scene, and each shader requires its own pipeline along with specific parameters. 
In certain scenarios, the parameters that configure a Bidirectional Reflectance Distribution Function (BRDF) are referred to as materials. 
Depending on the shader, each material requires specific settings. 
These settings may be shared across multiple objects, and to optimize GPU performance, meshes with identical material settings are often grouped and rendered sequentially.

In addition to shared material properties, each mesh also has its own unique attributes, which shaders use to render their triangles.

In Vulkan, uniform variables are organized into Sets, with each Set representing a level of update frequency. 
Each Set is identified by an ID, starting from 0, with lower IDs assumed to change less frequently. 
A single Set can contain various resources, such as:
\begin{itemize}
    \item Uniform blocks serving different purposes (e.g., light definitions, environmental properties).
    \item Textures.
    \item Other types of data.
\end{itemize}
Resources within a Set are identified by a secondary index called the Binding, which also starts from zero. Multiple resource types can be accessed as global Uniform Variables.

In this context, three key concepts are crucial:
\begin{itemize}
    \item Descriptor Set Layouts.
    \item Descriptor Sets.
    \item Pipeline Layouts.
\end{itemize}

\paragraph*{Descriptor Set Layouts}
In object-oriented programming (OOP) terms, Descriptor Set Layouts can be thought of as the "class" of uniform variables. They define the following:
\begin{itemize}
    \item The type of descriptors (e.g., uniform buffer, texture image).
    \item The binding ID associated with each descriptor.
    \item The shader stage(s) in which the descriptors will be used (e.g., Vertex Shader, Fragment Shader, or both).
\end{itemize}

Descriptor Layouts within the same set, but with different bindings, are specified in an array of \texttt{VkDescriptorSetLayoutBinding} structures. 
Each binding in this array defines an integer ID starting from zero, the descriptor type (e.g., Uniform, Texture sampler), and the Shader Stage(s) that can access it.

Uniform blocks can be defined as arrays containing multiple elements. 
Additionally, if a texture is consistent across all pipelines in which it appears, certain optimizations may be possible. 
However, these advanced topics are beyond the scope of this course.

The \texttt{VkDescriptorSetLayout} objects are created using the \\\texttt{vkCreateDescriptorSetLayout} function.
This function takes a \\\texttt{VkDescriptorSetLayoutCreateInfo} structure as an argument, which includes a pointer to the binding array and the number of elements in the array.

\paragraph*{Descriptor Sets}
In object-oriented programming (OOP) terms, Descriptor Sets are instances of uniform data. 
They define the actual values that will be passed to the uniforms. 
For example, different meshes using the same material but requiring distinct world matrices will access different Descriptor Sets, each associated with the same Descriptor Layout.

\paragraph*{Pipeline Layout}
The Pipeline Layout specifies which Descriptor Layouts will be accessed by the shaders in a given pipeline. 
It also defines the Set IDs where these descriptors will be found in the shaders.
Descriptor sets are grouped into an array and provided in the \texttt{pSetLayouts} field of the \texttt{VkPipelineLayoutCreateInfo} structure, which is used to create the \texttt{VkPipelineLayout} with the \texttt{vkCreatePipelineLayout} function. 
The number of sets in the array is indicated by the \texttt{setLayoutCount} field.

The position of each layout in the array corresponds to the Set ID that the shader code will use to access the associated Descriptor Set.


\paragraph*{Descriptor Pools}
Descriptor sets must be allocated from a Descriptor Pool, similar to how Command Buffers are allocated. 
However, this process is somewhat more complex because an accurate estimate of the number of sets is required.

A Descriptor Pool is defined by a set of \texttt{VkDescriptorPoolSize} objects, each specifying the type and quantity of descriptors (using the \texttt{descriptorCount} field). 
This array of descriptor requests is used to populate a \texttt{VkDescriptorPoolCreateInfo} structure, which also requires specifying the maximum number of descriptor sets that the application will use.

Determining the correct number of descriptors and descriptor sets needed by an application can be challenging, as it depends heavily on the structure of the rendering engine. 
The number should be equal to the sum of the different Descriptor Sets and the elements of each type used in the application.

Descriptor Pools are necessary for allocating Descriptor Sets using the \\\texttt{vkAllocateDescriptorSets()} function, with the allocation details provided in a \\\texttt{VkDescriptorSetAllocateInfo} structure. 
The function returns an array of \texttt{VkDescriptorSet} handles, each representing a descriptor set instance.

Descriptor Sets instantiate the Descriptor Layouts: typically, at least one Descriptor Set is needed for each unique value assigned to a Uniform. 
For Uniforms that change with the Scene, one set per scene is required; for those that change with the material, one set per material, and so on.

The method for linking Descriptor Set handles to their corresponding objects varies depending on the type of descriptor. 
This process shares similarities with defining vertex layouts.

\subsection{Descriptor Buffers}
First, a C++ data structure is created to store the variables that need to be sent to the shader. Instances of this structure reside in CPU memory (i.e., RAM). 
To be accessible within the shader, this data must be transferred to GPU-accessible memory (i.e., VRAM).

GPU memory may have specific alignment requirements that must also be respected in the C++ structure. 
This alignment can be managed using the \texttt{alignas()} C++ keyword.

Memory buffers are used to store and retrieve information from GPU-accessible video memory. 
They are characterized by two handles: a \texttt{VkBuffer} that identifies the buffer as a whole, and a \texttt{VkDeviceMemory} object that describes the allocated memory.

Once the descriptors have been set up, the application can update them in three steps:
\begin{enumerate}
    \item Acquire a pointer to a memory area where the CPU can write the data, using the \texttt{vkMapMemory()} command.
    \item Fill this memory area with the new values, typically using the \texttt{memcpy()} function.
    \item Trigger the update of the video memory by calling \texttt{vkUnmapMemory()}.
\end{enumerate}

\subsection{Binding and Textures}
Shaders must match the data types and order of the corresponding CPU objects. 
Additionally, they should use the same Set and Binding IDs defined in the application.

Textures are passed to shaders through special Layout Bindings within Set Layouts. 
When creating the Descriptor Pool, a request for the Combined Image Sampler must be included to support textures.

The actual texture pointer is specified when creating the Descriptor Set object associated with the Descriptor Set Layout. 
The \texttt{VkWriteDescriptorSet} structure, in addition to specifying the correct binding, indicates that this descriptor is a Combined Image Sampler.

Textures are passed to shaders as specific uniform variables of the Combined Texture Sampler type. 
To sample a texture, the shader uses the \texttt{texture()} function. 
The first parameter of this function specifies the image, while the second parameter defines the texel coordinates (format dependent on the sampler type). 
The function returns a \texttt{vec4} color, where the last component represents the alpha channel (transparency).

\subsection{Texturing}
Vulkan allows specifying a texture and its sampler in two distinct uniforms. 
This option is not covered in this course, so we will not delve into it further.

Each Graphics Adapter has its own internal format for images.
Texture sampling, which involves numerous interpolations and floating-point operations, is managed by special hardware blocks on the GPU called Texture Units. 
The source image provided by the application usually differs from the format used internally by the GPU. 
Therefore, the input texture data must be converted into a format that the GPU and its Texture Units can process more efficiently.

In OpenGL and other graphics systems, this format conversion was handled automatically by the drivers without requiring special developer intervention. 
Vulkan, however, requires developers to explicitly manage this process.

The texturing stages are:
\begin{itemize}
    \item \textit{Loading}: The first step in defining a texture is loading the image into a memory area accessible by the CPU. 
        This can be done using libraries such as \texttt{stb\_image}. Specifically, the \texttt{stbi\_load()} function returns an array of RGBA pixels along with the texture's size information.
        Size measurements can help determine other important details such as memory requirements and the number of Mip-Map levels.
    \item \textit{Staging Buffer}: The next step is to move the texture into a memory area accessible by the GPU, known as the Staging Buffer. 
        After the texture is placed in the staging buffer, the original memory area can be released. 
        Finally, the texture must be transferred to its designated memory area, and its format converted to one recognized by the GPU.
\end{itemize}

\paragraph*{Mip-mapping}
In older graphics engines like OpenGL, Mip-Map generation was handled by the driver, with the option for the developer to provide the Mip-Map layers directly. 
In Vulkan, however, the entire process of Mip-Map generation must be managed by the user.