\begin{abstract}
    Neural networks have matured into flexible and powerful non-linear data-driven models, effectively tackling complex tasks in both science and engineering. 
    The emergence of deep learning, which utilizes neural networks to learn optimal data representations alongside their corresponding models, has significantly advanced this paradigm.

    In the course, we will explore various topics in depth.
    We will begin with the evolution from the Perceptron to modern neural networks, focusing on the feedforward architecture. 
    The training of neural networks through backpropagation and algorithms like Adagrad and Adam will be covered, along with best practices to prevent overfitting, including cross-validation, stopping criteria, weight decay, dropout, and data resampling techniques.
    
    The course will also delve into specific applications such as image classification using neural networks, and we will examine recurrent neural networks and related architectures like sparse neural autoencoders. 
    Key theoretical concepts will be discussed, including the role of neural networks as universal approximation tools, and challenges like vanishing and exploding gradients.
    
    We will introduce the deep learning paradigm, highlighting its distinctions from traditional machine learning methods.
    The architecture and breakthroughs of convolutional neural networks (CNNs) will be a focal point, including their training processes and data augmentation strategies.
    
    Furthermore, we will cover structural learning and long-short term memory (LSTM) networks, exploring their applications in text and speech processing. 
    Topics such as autoencoders, data embedding techniques like word2vec, and variational autoencoders will also be addressed.
    
    Finally, we will discuss transfer learning with pre-trained deep models, examine extended models such as fully convolutional CNNs for image segmentation (e.g., U-Net) and object detection methods (e.g., R-CNN, YOLO), and explore generative models like generative adversarial networks (GANs).
\end{abstract}