\section{Model definition}

We need to find the number of features and the number of classis for our Neural Network. 
We set also the other parametes such as: batch size (number of samples processed in each training iteration), number of epochs (times the entire dataset is passed through the network during training).

\begin{lstlisting}[style=Python]
input_shape = X_train.shape[1:]
batch_size = 64
epochs = 1000
metadata = {}
\end{lstlisting}
We can finally build the model.
\begin{lstlisting}[style=Python]
def build_model(input_shape, learning_rate=1e-3, l2_lambda=0, dropout_rate=0, name='', seed=seed):

    # Set random seed for reproducibility
    tf.random.set_seed(seed)

    # Initialise weights and regulariser
    initialiser = tfk.initializers.GlorotNormal(seed=seed)
    regulariser = tfk.regularizers.l2(l2_lambda)

    # Input layer
    input_layer = tfkl.Input(shape=input_shape, name='Input')

    # Hidden layers with ReLU activations
    x = tfkl.Dense(units=256, name='HiddenDense1', kernel_initializer=initialiser)(input_layer)
    x = tfkl.Activation('relu', name='HiddenActivation1')(x)
    x = tfkl.Dense(units=256, name='HiddenDense2', kernel_initializer=initialiser)(x)
    x = tfkl.Activation('relu', name='HiddenActivation2')(x)

    # Dropout layer if specified
    if dropout_rate > 0:
    x = tfkl.Dropout(dropout_rate, seed=seed, name='Dropout')(x)

    # Output layer with optional L2 regularisation
    if l2_lambda > 0:
    output_layer = tfkl.Dense(units=1, kernel_initializer=initialiser, kernel_regularizer=regulariser, name='Output')(x)
    else:
    output_layer = tfkl.Dense(units=1, kernel_initializer=initialiser, name='Output')(x)

    # Linear output activation
    output_activation = tfkl.Activation('linear', name='OutputActivation')(output_layer)

    # Connect input and output through the Model class
    model = tfk.Model(inputs=input_layer, outputs=output_activation, name=name)

    # Compile the model with Adam optimiser and MSE loss
    opt = tfk.optimizers.Adam(learning_rate)
    loss = tfk.losses.MeanSquaredError()
    mtr = ['mse']
    model.compile(loss=loss, optimizer=opt, metrics=mtr)

    # Return the compiled model
    return model
\end{lstlisting}
Now we can finally display the data about the new model we have created. 
\begin{lstlisting}[style=Python]
model = build_model(input_shape)
model.summary(expand_nested=True, show_trainable=True)
tfk.utils.plot_model(model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)
\end{lstlisting}
