\section{Complexity analysis}

The running time of an algorithm varies with the input; for instance, sorting an already sorted sequence is less complex. 
Therefore, we often parameterize running time by the input size, as shorter sequences are typically easier to sort than longer ones. 
Generally, we aim for upper bounds on running time, as guarantees are desirable.

Running time analysis can be categorized into three main types:
\begin{itemize}
    \item \textit{Worst-case} (most common): here, $T(n)$ represents the maximum time an algorithm takes on any input of size $n$. 
    This is particularly relevant when time is a critical factor.
    \item \textit{Average-case} (occasionally used): in this case $T(n)$ reflects the expected time of the algorithm across all inputs of size $n$. 
    It requires assumptions about the statistical distribution of inputs.
    \item \textit{Best-case} (often misleading): this scenario highlights a slow algorithm that performs well on specific inputs.
\end{itemize}
To establish a general measure of complexity, we focus on a machine-independent evaluation.
This involves disregarding machine-dependent constants or analyzing the growth of $T(n)$ as $n$ approaches infinity.
This framework is called asymptotic analysis. 

As the input length $n$ increases, algorithms with lower complexity will outperform those with higher complexities. 
However, asymptotically slower algorithms should not be dismissed, as real-world design often requires a careful balance of various engineering objectives. 
Thus, asymptotic analysis serves as a valuable tool for crafting solutions to specific problems.

\subsection{Theta notation}
In mathematical terms, the theta notation is defined as:
\[\Theta\left(g(n)\right)=f(n)\]
Here, $f(n)$ satisfies the existence of positive constants $c_1$, $c_2$, and $n_0$ such that $0 \leq c_1 \cdot g(n) \leq f (n) \leq c_2 \cdot g(n)$ for all $n \geq n_0$. 

In engineering practice, we typically ignore lower-order terms and constants.
\begin{example}
    Consider the following expression: 
    \[3n^3+90n^2-5n+6046\]
    The corresponding theta notation is:
    \[\Theta(n^3)\]
\end{example}

From theta notation, we can also define:
\begin{itemize}
    \item \textit{Upper bound}:
        \[O(g(n))=f(n)\]
        Here, $f(n)$ meets the condition that there exist constants $c > 0$ and $ n_0 > 0$ such that $0 \leq f(n) \leq c \cdot g(n)$ for all $n \geq n_0$. 
    \item \textit{Lower bound}:
        \[\Omega(g(n))=f(n)\]
        Here, $f(n)$ meets the condition that there exist constants $c > 0$ and $ n_0 > 0$ such that $0 \leq c \cdot g(n) \leq f(n)$ for all $n \geq n_0$. 
    \item \textit{Strict upper bound}: the strict upper bound is defined as: 
        \[o(g(n))=f(n)\]
        Here, $f(n)$ meets the condition that there exist constants $c > 0$ and $ n_0 > 0$ such that $0 \leq f(n) < c \cdot g(n)$ for all $n \geq n_0$. 
    \item \textit{Strict lower bound}: the strict lower bound is defined as: 
        \[\omega(g(n))=f(n)\]
        Here, $f(n)$ meets the condition that there exist constants $c > 0$ and $ n_0 > 0$ such that $0 \leq c \cdot g(n) < f(n)$ for all $n \geq n_0$. 
\end{itemize}
\begin{example}
    For the expression $2n^2$: 
    \[2n^2 \in O(n^3)\]
    For the expressio $\sqrt{n}$: 
    \[\sqrt{n} \in \Omega(\ln(n))\]
\end{example}
From this, we can redefine the strict bound as:
\[\Theta(g(n))=O(g(n))\cap\Omega(g(n))\]

\subsection{Sorting problem}
The sorting problem involves taking an array of numbers $\left\langle a_1,a_2,\dots,a_n \right\rangle$ and returning the permutation $\left\langle a_1^\prime,a_2^\prime,\dots,a_n^\prime \right\rangle$ such that $a_1^\prime\leq a_2^\prime \leq \dots \leq a_n^\prime$. 

\paragraph*{Insertion sort}
One approach to solving this problem is the insertion sort algorithm, which takes an array $A[n]$ as input.
\begin{algorithm}[H]
    \caption{Insertion sort}
        \begin{algorithmic}[1]
            \For{$j := 2$ \textbf{to} $n$} 
                \State $key := A[j]$
                \State $i := j-1$
                \While{$i > 0$ \textbf{and} $A[i]>key$}
                    \State $A[i+1] := A[i]$
                    \State $i := i - 1$
                \EndWhile
                \State $A[i+1] := key$
            \EndFor
        \end{algorithmic}
\end{algorithm}
For insertion sort, the worst-case scenario occurs when the input is sorted in reverse order, leading to a complexity of:
\[T_{\text{worst}}(n)=\sum_{j=2}^n\Theta(j)=\Theta(n^2)\]
For the average case, assuming all permutations are equally likely, the complexity is:
\[T(n)_{\text{average}}=\sum_{j=2}^n\Theta\left(\dfrac{j}{2}\right)=\Theta(n^2)\]
In the best-case scenario, where the list is already sorted, we only need to check each element:
\[T(n)_{\text{best}}=\sum_{j=2}^n\Theta\left(1\right)=\Theta(n)\]
In conclusion, while this algorithm performs well for small $n$, it becomes inefficient for larger input sizes.