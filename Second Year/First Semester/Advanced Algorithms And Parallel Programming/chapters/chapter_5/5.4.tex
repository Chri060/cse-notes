\section{PCAM design}

1 Partitioning =>
task/data decomposition
2 Communication => task
execution coordination
3 Agglomeration =>
evaluation of the
structure
4 Mapping => resource
assignment
❑ In practice, these steps
are often overlapping

\subsection{Partitioning}
Partitioning stage is intended to expose
opportunities for parallel execution in the given
problem
❑ Focus on defining large number of small tasks to
yield a fine-grained decomposition of the problem
❑ A good partition divides into small pieces both the
computational tasks associated with a problem and
the data on which the tasks operate, without
replications
❑ There are two approaches to partitioning:
⚫ Domain decomposition
⚫ Functional decomposition
❑ Mixing domain/functional decomposition is possible
Domain (data) Decomposition
❑ The data associated with a problem is decomposed
❑ Each parallel task then works on a portion of the
data
❑ When possible, portions should be small and of
equal size
Functional Decomposition
❑ The focus is on the computation that is to be
performed rather than on the data manipulated by
the computation
❑ The problem is decomposed according to the work
that must be done
Functional Decomposition:
Ecosystem Modeling
❑ Each task calculates the population of a group,
whose growth depends on that of its neighbors
❑ As time progresses, each process calculates its
current state, then exchanges information with the
neighbor populations
❑ All tasks then progress to calculate the state at the
next time step
Functional Decomposition: Signal
Processing
❑ An audio signal data set is passed through four
distinct computational filters
❑ The first segment of data must pass through the
first filter before progressing to the second. When
it does, the second segment of data passes
through the first filter. By the time the fourth
segment of data is in the first filter, all four tasks
are busy
Checklist:
❑ Does your partition define at least an order of
magnitude more tasks than there are processors
in your target computer? If not, may lose design flexibility.
❑ Does your partition avoid redundant computation
and storage requirements? If not, may not be scalable.
❑ Are tasks of comparable size? If not, it may be hard to
allocate each processor equal amounts of work.
❑ Does the number of tasks scale with problem size?
If not, may not be able to solve larger problems with more
processors
❑ Have you identified several alternative partitions?

\subsection{Communication}
Tasks generated by a partition must interact to allow
the computation to proceed
⚫ Information flow: channel and message
❑ Types of communication
⚫ Local vs. Global: small set of neighbors or many
tasks (possibly at the same time)
⚫ Structured vs. Unstructured: regular (tree, grid) or
arbitrary communication patterns
⚫ Static vs. Dynamic: identity of communication
partners can be determined by runtime conditions
⚫ Synchronous vs. Asynchronous: coordination
degree producer/consumer
⚫ (Explicit vs. Implicit, implementation dependent)
Point-to-point - involves two tasks with one task
acting as the sender/producer of data, and the
other acting as the receiver/consumer. Unfeasible
for global communications!
❑ Collective - involves
data communication
between more than two
tasks, which are often
specified as being
member of a common
group, or collective. 
When we move to the architecture-dependent
implementation phases, communication is
probably the most critical aspect
❑ Communication overhead cost can nullify the
benefits of the parallelization itself
❑ Overhead is due to:
Transmission
Synchronization
❑ Try to minimize the number of channels and
organize communication to allow concurrent
execution
Overlap communication and computation
Checklist:
❑ Is the distribution of communications equal
among tasks? Unbalanced communication may limit scalability
❑ What is the communication locality? Many point-topoint communications are expensive
❑ What is the degree of communication
concurrency? Communication operations may be parallelized
❑ Is computation associated with different tasks
able to proceed concurrently? Can communication
be overlapped with computation? Try to reorder
computation and communication to expose opportunities for
parallelism

\subsection{Agglomeration}
Move from parallel abstractions to real
implementation
❑ Revisit partitioning and communication to get
efficiency on a particular parallel architecture
❑ Reduce number of tasks, combine them into larger
ones (increased granularity, reduced
communication)
❑ Replicate data and/or computation if it can be useful
❑ Maintain flexibility to allow scalability, portability and
future mapping decisions
⚫ Load balancing
⚫ Computation/communication overlapping
Agglomeration changes important algorithm and
performance ratios
⚫ Consider that also task creation has an overhead
⚫ Reduce the number of messages where the size of
transferred data can’t be reduced
❑ Surface-to-volume: increase in task size, reduction in
communication
⚫ Communication/computation ratio decreases
⚫ Efficiency increases
⚫ Parallelism decreases
⚫ Agglomerate in all dimensions!
⚫ Always beneficial if there are tasks that cannot
execute concurrently
Checklist:
❑ Has increased locality reduced communication
costs?
❑ Is replicated computation worth it? Does data
replication compromise scalability?
❑ Are tasks still balanced in terms of computation
and communication?
❑ Does the number of tasks still scale with problem
size?
❑ Is there still sufficient concurrency?
❑ Is there room for more agglomeration?

\subsection{Mapping}
Specify where each task shall be executed
⚫ Less of a concern on shared-memory systems
❑ Attempt to minimize execution time
⚫ Place concurrent tasks on different processors to
enhance physical concurrency (parallelism)
⚫ Place communicating tasks on same processor, or
on processors close to each other, to increase
locality
⚫ Strategies can conflict!
⚫ Possible resource limitations
Mapping problem is NP-complete, heuristics needed
❑ Load balancing (partitioning) algorithms
⚫ Static or dynamic
❑ Task-based (task scheduling) algorithms
⚫ Used when functional decomposition yields many
tasks with weak locality requirements
⚫ Use task assignment to keep processors busy
computing
⚫ Consider centralized and decentralized schemes
Checklist:
❑ Is static mapping too restrictive and nonresponsive?
❑ Is dynamic mapping too costly in overhead?
❑ Does centralized scheduling lead to bottlenecks?
❑ Do dynamic load-balancing schemes require too
much coordination to re-balance the load?
❑ What is the tradeoff of dynamic scheduling
complexity versus performance improvement?
❑ Are there enough tasks to achieve high levels of
concurrency? If not, processors may idle