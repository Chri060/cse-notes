\section{Introduction}

Historically, both developers and users have approached problem-solving with a sequential mindset. 
This approach is reflected in the majority of existing algorithms, which are designed to execute one step at a time in a linear fashion. 
However, modern hardware architectures offer significant opportunities for parallelism, allowing for the simultaneous execution of multiple instructions or tasks.

Parallelism provides several key advantages:
\begin{itemize}
    \item \textit{Time efficiency}: parallel algorithms can complete tasks faster than their sequential counterparts, reducing overall processing time.
    \item \textit{Cost efficiency}: systems built on parallel architectures with multiple inexpensive components can often be more cost-effective than single-processor systems using high-cost components.
    \item \textit{Tackling complex problems}: parallelism enables the solution of highly complex problems that are often intractable for sequential algorithms.
\end{itemize}

\paragraph*{Moore's law}
The rapid performance improvements of single-core processors are beginning to slow down. 
According to Moore's Law, the number of transistors on a chip doubles approximately every 24 months, but single cores can no longer fully utilize the additional transistors. 
Moreover, continually increasing processor frequency has become impractical due to rising power consumption and heat dissipation concerns. 
Consequently, parallelism is increasingly essential to leverage these advances and continue improving computational performance.