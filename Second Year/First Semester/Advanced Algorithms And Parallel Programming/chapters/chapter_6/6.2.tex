\section{Aggregate method}

The amortized cost analysis in the aggregate method provides an average cost per operation over a sequence of operations, even if individual operations can sometimes be costly. 
This approach is particularly useful for data structures that undergo periodic costly operations because it spreads the cost of these occasional expensive operations across many cheaper ones.

\paragraph*{Hash table resizing}
Although a single insertion might seem costly in the worst-case scenario, with a time complexity of $\mathcal{O}(n)$, this does not mean that $n$ insertions would collectively cost $\mathcal{O}(n^2)$. 
In practice, the total cost for $n$ insertions remains close to $\mathcal{O}(n)$, resulting in far greater efficiency.

To illustrate this, let the insertion cost of the $i$-th entry be represented as $c_i$:
\[c_i=\begin{cases}
    i \qquad\text{if }i - 1 \text{ is an exact power of }2 \\
    1 \qquad\text{otherwise}
\end{cases}\]
When $i - 1$ is an exact power of 2, the table size doubles, requiring all existing entries to be reinserted. 
For all other insertions, the cost remains 1.

Thus, the amortized cost per insertion is $\mathcal{O}(1)$, meaning that each insertion, on average, is a constant-time operation. 
This amortized efficiency allows dynamic hash tables to effectively manage an unpredictable number of entries while ensuring consistent performance.