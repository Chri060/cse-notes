\section{Introduction}

Information retrieval is the task of finding relevant content that match a user's information need.
To achieve this, we typically extract keywords from the user's query and search for documents containing those keywords.

\paragraph*{Vocabulary matching}
A simple but effective approach in text retrieval is vocabulary matching. 
If the vocabulary is well-distributed across documents, we can use fast indexing techniques to quickly locate relevant documents. 
However, this method has limitations.
Some queries may not have an exact match in the document collection.
Many documents might contain all the query terms, making it difficult to rank them effectively.
To address these challenges, we can: 
\begin{itemize}
    \item Assign scores to keywords based on how discriminative they are.
    \item Expand document representations by incorporating additional signals, such as page importance.
    \item Train ML models to improve retrieval performance.
\end{itemize}

\paragraph*{Classifier}
An alternative approach is to train a classifier that directly predicts the relevance of a document to a query. 
This involves representing both the query and the document as a combined feature vector and predicting the probability that a user finds the document relevant to the query.
However, this approach presents several challenges:
\begin{itemize}
    \item A simple linear classifier would fail to capture complex interactions between query and document terms.
    \item A non-linear model that accounts for pairwise term interactions would be extremely large.
    \item Training such a model would require massive labeled datasets of (query, document, relevance) pairs.
    \item Retrieval speed would suffer if we had to score every document individually.
\end{itemize}
