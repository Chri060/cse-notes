\section{Ethics}

Ethical considerations are foundational in the design and deployment of artificial agents. 
From early fictional warnings such as Mary Shelley's Frankenstein, which depicted the dangers of creating intelligent beings without regard for moral responsibility, to modern real-world failures, the lesson is clear: neglecting ethical principles can have serious consequences.

Key areas of concern include:
\begin{itemize}
    \item \textit{Safety}: preventing harm caused by inappropriate or dangerous behavior.
    \item \textit{Representational harm}: avoiding reinforcement of stereotypes or marginalization of social groups.
    \item \textit{Privacy}: safeguarding users' personal data from leaks or misuse.
\end{itemize}

\subsection{Safety}
Ensuring the safety of users is paramount. 
Mental health chatbots must exercise extreme caution. 
A poorly worded response can have serious emotional consequences.
In-vehicle conversational agents must remain context-aware to avoid distracting the driver or compromising road safety.
Systems interacting with humans must be designed with rigorous guardrails to prevent unintended harm, especially when users may place implicit trust in the agentâ€™s responses.

\subsection{Representational harm}
If the training data contains biased or harmful content, the system is likely to reproduce it.
AI systems can reinforce and even normalize the harmful biases present in the datasets they learn from.
As a result, significant research efforts are now directed toward detecting, mitigating, and removing biased or toxic content from training data.

\subsection{Privacy}
Privacy concerns arise from both accidental and intentional information leakage. 
Designing privacy-preserving dialogue systems is a critical challenge moving forward. 
Developers must prioritize data minimization, local processing, and transparent data policies to earn and maintain user trust.