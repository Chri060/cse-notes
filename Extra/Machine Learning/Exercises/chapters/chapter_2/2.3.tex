\section{Exercise three}

Consider a binary classifier trained on a dataset comprising $N = 100$ samples.
\begin{enumerate}
    \item Given a precision of $0.25$ and an F1 score of $0.4$, compute the recall.
    \item Additionally, with an accuracy of $0.85$, calculate the complete confusion matrix.
    \item Under what circumstances is accuracy not a dependable metric for evaluating the model's quality?
\end{enumerate}

\subsection*{Solution}
\begin{enumerate}
    \item We have:
        \[\text{F1}=\dfrac{2\cdot\text{Pre}\cdot\text{Rec}}{\text{Pre}+\text{Rec}}=0.4\]
        \[\text{Pre}=\dfrac{TP}{TP+FP}=0.25\]
        We seek to find:
        \[\text{Rec}=\dfrac{TP}{TP+FN}\]
        Substituting, we obtain:
        \[\dfrac{2\cdot0.25\cdot\text{Rec}}{0.25+\text{Rec}}=0.4\rightarrow \text{Rec}=1\]
    \item Given:
        \[\text{F1}=\dfrac{2\cdot\text{Pre}\cdot\text{Rec}}{\text{Pre}+\text{Rec}}=0.4\]
        \[\text{Pre}=\dfrac{TP}{TP+FP}=0.25\]
        \[\text{Rec}=\dfrac{TP}{TP+FN}=1\]
        \[\text{Acc}=\dfrac{TP+TN}{N}=0.85\]
        We infer that $FN=0$ since the recall is unity. 
        Then, from the other formulas:
        \[\begin{cases}
            \text{TP}+\text{TN}=85 \\
            \text{FN}=0 \\
            \text{TP}=0.25(\text{TP}+\text{FP}) \\
            \text{TP}+\text{TN}+\text{FN}+\text{FP}=100
        \end{cases} \rightarrow \begin{cases}
            \text{TP}=5 \\
            \text{FN}=0 \\
            \text{FP}=15 \\
            \text{TN}=80
        \end{cases}\]
    \item Accuracy is not a reliable indicator of the model's quality primarily under two conditions: when the dataset is imbalanced, and when the consequences of misclassifying positive-class samples differ from misclassifying negative-class samples.
\end{enumerate}