\section{Equivalent formulation}

Consider a zero sum game described by a payoff matrix $P$. 
We can assume, without loss of generality, that $p_{ij}>0$ for all $i,j$.
This implies $v>0$.

If $\alpha_j=\frac{x_i}{v}$, then $\sum x_i=1$ becomes $\sum \alpha_i=\frac{1}{v}$ and maximizing $v$ is equivalent to minimizinf $\sum\alpha_i$.
Likewise, if we set $\beta_j=\frac{y_j}{v}$ we can do the same. 
Consider the two problems in duality: 
\[\begin{cases}
    \min (c,\alpha) \\
    A\alpha\geq b \\
    \alpha\geq 0
\end{cases} \qquad \begin{cases}
    \max (b,\beta) \\
    A^T\beta\leq c \\
    \beta\geq 0
\end{cases}\]
Here, $A=P^T$. 
Denote by $v$ the common value of the two problems.
Then we have: 
\begin{itemize}
    \item $x$ is the optimal strategy for Player 1 if and only if $x=v\alpha$ for some $\alpha$ optmal solution of the primal problem.
    \item $y$ is the optimal strategy for Player 2 if and only if $y=v\beta$ for some $\beta$ optmal solution of the dual problem.
\end{itemize}

Consider again the complementarity conditions for the above problems, with $x$ and $y$ being strategies for the two players: 
\[\begin{cases}
    \forall i \bar{x}_i>0 \implies\sum_{k=1}^mp_{ik}\bar{y}_k=c_i \\
    \forall i \bar{y}_i>0 \implies\sum_{k=1}^np_{kj}\bar{x}_k=b_i 
\end{cases}\]
Since $\bar{y}$ is optimal for Player 2, one has $\sum_{j=1}^mp_{ij}\bar{y}_j$ for all $i$, and hence $x_i>0$ implies that the row $i$ is optimal for Player 1.
And conversely the same holds for Player 2