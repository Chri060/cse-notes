\section{Optimality}

Let $X$ and $Y$ be arbitrary sets. 
Suppose:
\begin{enumerate}
    \item $v_1 = v_2 := v$.
    \item There exists a strategy $\bar{x}$ such that $f(\bar{x}, y) \geq v$ for all $y \in Y$.
    \item There exists a strategy $\bar{y}$ such that $f(x, \bar{y}) \leq v$ for all $x \in X$. 
\end{enumerate}
Then: 
\begin{itemize} 
    \item $v$ is the rational outcome of the game. 
    \item $\bar{x}$ is an optimal strategy for Player 1. 
    \item $\bar{y}$ is an optimal strategy for Player 2. 
\end{itemize}
It follows that $\bar{x}$ is optimal for Player 1 since it maximizes $\alpha(x) = \inf_y f(x, y)$, while $\bar{y}$ is optimal for Player 2 since it minimizes $\beta(y) = \sup_x f(x, y)$. 
The values $\alpha(x)$ and $\beta(y)$ represent the best responses for the players if they knew the opponent's strategy.

\subsection{Conservative values different or equal}
\begin{proposition}
    Let $X$ and $Y$ be nonempty sets, and let $f : X \times Y \rightarrow \mathbb{R}$ be an arbitrary real-valued function.
    Then: 
    \[v_1 = \sup_x\inf_yf (x, y) \leq \inf_y\sup_xf (x, y) = v_2\]
\end{proposition}
\begin{proof}
    By definition, for all $x \in X$ and $y \in Y$:
    \[\inf_yf(x, y) \leq f (x, y) \leq \sup_xf (x, y)\]
    Thus, for all $x$ and $y$, it holds that:
    \[\alpha(x) = \inf_yf (x, y) \leq \sup_xf (x, y) = \beta(y)\]
    Taking the supremum over $x$ and the infimum over $y$, we conclude:
    \[\sup_x\alpha(x) \leq \inf_y\beta(y)\]
\end{proof}
As a result, it follows that for any game, $v_1 \leq v_2$.
\begin{example}
    Consider the game of rock-paper-scissors, represented by the following matrix:
    \[\begin{pmatrix} 0 & 1 & -1 \\ -1 & 0 & 1 \\ 1 & -1 & 0 \end{pmatrix}\]
    The conservative values are not the same: in fact, $v_1 = -1$ and $v_2 = 1$. 

    Here, $v_1 = -1$ and $v_2 = 1$, indicating the conservative values are not equal. 
    Therefore, no single deterministic strategy guarantees a win. 
    However, in a repeated game with mixed strategies, both players should play each option with equal probability (one-third of the time), resulting in an expected utility of zero for both players.
\end{example}

\subsection{Conservative values not equal}
When the conservative values differ, mixed strategies must be considered. 
In this case, the strategy spaces for both players are probability distributions:
\[\sum_k=\left\{x=(x_1,\dots,x_k)|x_i\geq 0 \text{ and }\sum_{i=1}^{k}x_i=1\right\}\]
Here, $k = n$ for Player 1 and $k = m$ for Player 2. 
The utility function is extended to:
\[f(x,y)=\sum_{i=1,\dots,n,j=i,\dots,m}x_iy_jp_{ij}=(x,Py)\]
Thus, the mixed extension of the original game is given by:
\[\left(\sum_n, \sum_m, f (x, y) = (x, Py)\right)\]

\subsection{Pure strategies optimality}
\begin{theorem}
    If a player knows the strategy being used by the opposing player, they can always adopt a pure strategy to achieve the best possible outcome.
\end{theorem}
This means that once one player's choice is fixed, the optimization problem reduces to a linear problem over a simplex, given that the utility function in such a game is bilinear.
\begin{proof}
    Consider Player 2, who knows that Player 1 is using a mixed strategy $\bar{x}$. 
    Player 2's task is then to minimize the function:
    \[f (\bar{x}, y) = (\bar{x}, Py)\]
    over the simplex $\sum_m$ (the set of mixed strategies for Player 2). 
    The optimal value will be attained at one of the vertices $e_j$ of the simplex, which corresponds to a pure strategy.
    Thus, Player 2 can use a pure strategy to achieve the optimal outcome.
\end{proof}
Given a payoff matrix  $P$, let the column vector corresponding to the $j$-th pure strategy be denoted as $p_{\cdot j}$, and the row vector corresponding to the $i$-th pure strategy as $p_{i\cdot}$, respectively. 
The payoff of the first player in the mixed extension of the game is given by:
\[f(x,y)=(x,Py)\]
The previous theorem implies that, to verify the existence of a rational outcome for the game, we need to show the existence of mixed strategies $\bar{x}$ and $\bar{y}$, as well as a value $v$, such that: 
\begin{itemize}
    \item $(\bar{x},P_{e_j})=(\bar{x},p_{\cdot j})$ for every column $j$. 
    \item $(e_i,p_{i\cdot}\bar{y})\leq v$ for every row $i$.
\end{itemize}
Here, $e_j$ is the $j$-th strategy of Player 2, and $e_i$ is the $i$-th strategy of Player 1.
\begin{example}
    Consider the following payoff matrix of a game: 
    \[P=\begin{pmatrix} 7 & 1 & 4 & 9 \\ 3 & 10 & 6 & 2 \\ 4 & 5 & 3 & 0 \end{pmatrix}\]
    The third row is trictly dominated by a convex combination of the first two. 
    Thus, the payoff matrix can be reduced to: 
    \[P=\begin{pmatrix} 7 & 1 & 4 & 9 \\ 3 & 10 & 6 & 2 \end{pmatrix}\]
    Now the set $C$ is the polygon with the following vertices: 
    \[\begin{pmatrix} 7 & 3 \end{pmatrix}\qquad\begin{pmatrix} 1 & 10 \end{pmatrix}\qquad\begin{pmatrix} 4 & 6 \end{pmatrix}\qquad\begin{pmatrix} 9 & 2 \end{pmatrix}\]
    The separating hyperplane is $\frac{1}{2}p_{1j}+\frac{1}{2}p_{2j}=5$, computed on $j=1$ or $j=3$.
    This means that $\mathbf{x}=\begin{pmatrix} \frac{1}{2} & \frac{1}{2} & 0 \end{pmatrix}$ is the optimal strategy of Player 1. 

    Moreover, this indicates that the value of the game is $v=5$. 

    For the other player, instead, we need to obtain $\begin{pmatrix} 5 & 5 \end{pmatrix}$ as the result of a convex combination of the vectors in the first and third columns, while the probability of the second and fouth columns is $y_2=0$ and $y_4=0$, one shows that $\begin{pmatrix} \frac{1}{2} & 0 & \frac{2}{3} & 0 \end{pmatrix}$ is the optimal strategy for Player 2.
\end{example}

\subsection{General case otimality}
Von Neumann proof can be efficiently used to find rational outcome of payoff matrices that can be reduced to matrices where ine player has only two strategies. 
However, in higher dimensions this procedure becomes more complicateds, since it is not clear when and where the set $Q_t$ meets $C$. 
Therefore, we need to use Linear Programmming. 

\paragraph*{Player one}
Player 1 must choose a probability distribution $\mathbf{x}=\begin{pmatrix} x_1 & \cdots & x_n \end{pmatrix} \in \sum_n$ in order to maximize $v$ with the following constraints: 
\[\begin{cases}
    (x,p_{\cdot,1})=x_1p_{11}+\dots+x_np_{n1}\geq v \\
    \cdots \\
    (x,p_{\cdot,j})=x_1p_{1j}+\dots+x_np_{nj}\geq v \\
    \cdots \\
    (x,p_{\cdot,m})=x_1p_{1m}+\dots+x_np_{nm}\geq v
\end{cases}\]
It is a linear maximization problem where we need to find the value $v$ and we do not know the vector $\mathbf{x}$.
In matrices, we have: 
\[\begin{cases}
    \min_{\mathbf{x},v}v: \\
    P^T\mathbf{x} \geq v\mathbf{1}_{m} \\
    \mathbf{x}\geq 0 \qquad \begin{pmatrix} 1 & \mathbf{x} \end{pmatrix} = 1
\end{cases}\]

\paragraph*{Player two}
Player 2 must choose a probability distribution $\mathbf{y}=\begin{pmatrix} y_1 & \cdots & y_m \end{pmatrix} \in \sum_m$ in order to maximize $w$ with the following constraints: 
\[\begin{cases}
    (x,p_{1,\cdot})=x_1p_{11}+\dots+x_mp_{1m}\leq w \\
    \cdots \\
    (x,p_{i,\cdot})=x_1p_{i1}+\dots+x_mp_{im}\leq w \\
    \cdots \\
    (x,p_{n,\cdot})=x_1p_{n1}+\dots+x_mp_{nm}\leq w 
\end{cases}\]
It is a linear maximization problem where we need to find the value $w$ and we do not know the vector $\mathbf{y}$.
In matrices, we have: 
\[\begin{cases}
    \min_{\mathbf{y},w}w: \\
    P\mathbf{y} \leq w\mathbf{1}_{n} \\
    \mathbf{y}\geq 0 \qquad \begin{pmatrix} 1 & \mathbf{y} \end{pmatrix} = 1
\end{cases}\]
Here, $\mathbf{1}$ is a vector of right dimensions whose componenst are all 1's.
Ideally, the maximum value for $v$ is equal to the minimal value for $w$, so as to yield the value of the game.
